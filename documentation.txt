üéØ PROJET OPTIMIS√â - ASSISTANT IA LOW-COST (VERSION PRODUCTION)
Je vais vous donner la meilleure version ex√©cutable avec extraction compl√®te des donn√©es et architecture optimale.

üìä STRUCTURE PROJET OPTIMIS√âE
text
assistant-ia-lowcost/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ backend/                          # Backend optionnel (Flask)
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ model_quantized.onnx
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data-collection/                  # Scripts collecte donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ 01_scraper_advanced.py          # Scraper complet
‚îÇ   ‚îú‚îÄ‚îÄ 02_pdf_extractor.py             # Extraction PDFs
‚îÇ   ‚îú‚îÄ‚îÄ 03_data_cleaner.py              # Nettoyage
‚îÇ   ‚îú‚îÄ‚îÄ 04_faq_generator.py             # G√©n√©ration FAQ
‚îÇ   ‚îú‚îÄ‚îÄ 05_embeddings_creator.py        # Cr√©ation embeddings
‚îÇ   ‚îú‚îÄ‚îÄ 06_model_quantizer.py           # Quantification mod√®le
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ üìÅ frontend/                         # Application React
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ faqs.json              # ‚úÖ FAQ compl√®tes
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.json        # ‚úÖ Embeddings
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json          # M√©tadonn√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tiny-model.onnx        # Mod√®le quantifi√©
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manifest.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service-worker.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ robots.txt
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Chat/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatInterface.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MessageBubble.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ InputBox.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ChatHeader.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UI/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ConnectionBadge.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LanguageSwitch.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ LoadingSpinner.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Widget/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ EmbeddableWidget.jsx
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aiEngine/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AIService.js       # Orchestrateur principal
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OfflineEngine.js   # Mode offline
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ HybridEngine.js    # Mode hybride
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OnlineEngine.js    # Mode online
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IndexedDBManager.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CacheManager.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ONNXRunner.js      # Ex√©cution ONNX
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RAGService.js      # Retrieval
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ EmbeddingService.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ APIService.js
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contexts/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AppContext.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ConnectionContext.jsx
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useChat.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useConnection.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useAI.js
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ similarity.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ textProcessing.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.js
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ locales/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fr.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ar.json
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ styles/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ global.css
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.css
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rtl.css
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ i18n.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.jsx
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ .env.example
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docs/                             # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md                  # Architecture d√©taill√©e
‚îÇ   ‚îú‚îÄ‚îÄ INSTALLATION.md                  # Guide installation
‚îÇ   ‚îú‚îÄ‚îÄ API_DOCUMENTATION.md             # Doc API
‚îÇ   ‚îú‚îÄ‚îÄ DEPLOYMENT.md                    # Guide d√©ploiement
‚îÇ   ‚îî‚îÄ‚îÄ assets/
‚îÇ       ‚îú‚îÄ‚îÄ architecture-diagram.png
‚îÇ       ‚îî‚îÄ‚îÄ demo-screenshots/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/                            # Tests
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aiService.test.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ragService.test.js
‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îÇ       ‚îî‚îÄ‚îÄ offline-mode.test.js
‚îÇ
‚îú‚îÄ‚îÄ üìÅ integration/                      # Int√©gration Nuit de l'Info
‚îÇ   ‚îú‚îÄ‚îÄ widget.html                      # Widget embeddable
‚îÇ   ‚îú‚îÄ‚îÄ integration-guide.md
‚îÇ   ‚îî‚îÄ‚îÄ demo.html
‚îÇ
‚îú‚îÄ‚îÄ üìÅ deployment/                       # Config d√©ploiement
‚îÇ   ‚îú‚îÄ‚îÄ vercel.json
‚îÇ   ‚îú‚îÄ‚îÄ netlify.toml
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ README.md                            # README principal
üî• PHASE 1: COLLECTE DONN√âES AVANC√âE (2-3h)
FICHIER: data-collection/requirements.txt
text
beautifulsoup4==4.12.3
requests==2.31.0
selenium==4.16.0
pdfplumber==0.10.3
PyPDF2==3.0.1
sentence-transformers==2.3.1
torch==2.1.2
transformers==4.36.2
onnx==1.15.0
onnxruntime==1.16.3
optimum==1.16.1
pandas==2.1.4
numpy==1.26.2
tqdm==4.66.1
lxml==5.1.0
langdetect==1.0.9
FICHIER: data-collection/01_scraper_advanced.py
python
"""
Scraper avanc√© avec Selenium pour site dynamique
Extraction compl√®te: textes, liens, images, PDFs, formulaires
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import requests
import json
import time
import os
from urllib.parse import urljoin, urlparse
import re

class AdvancedScraper:
    def __init__(self, base_url='https://www.nuitdelinfo.com'):
        self.base_url = base_url
        
        # Configuration Chrome headless
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 Educational Bot')
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.wait = WebDriverWait(self.driver, 15)
        
        # Stockage donn√©es
        self.all_data = {
            'metadata': {
                'source': base_url,
                'scrape_date': time.strftime('%Y-%m-%d %H:%M:%S'),
                'total_pages': 0
            },
            'pages': [],
            'faqs': [],
            'challenges': [],
            'rules': [],
            'links': [],
            'images': [],
            'pdfs': []
        }
        
        # Cr√©er dossiers
        os.makedirs('../frontend/public/data', exist_ok=True)
        os.makedirs('temp/pdfs', exist_ok=True)
        os.makedirs('temp/images', exist_ok=True)
    
    def scrape_complete_site(self):
        """Scraper complet du site"""
        print("="*80)
        print("üöÄ SCRAPING AVANC√â - NUIT DE L'INFO 2025")
        print("="*80)
        
        # Pages √† scraper
        pages = {
            'home': '/',
            'about': '/index.php?page=about',
            'challenges': '/inscription/defis/liste',
            'faq': '/faq',
            'rules': '/reglement',
            'inscription': '/inscription',
            'archives': '/archives'
        }
        
        for name, path in pages.items():
            print(f"\nüìÑ Scraping: {name} ({path})")
            self.scrape_page(path, name)
            time.sleep(2)
        
        # Scraper d√©fis sp√©cifiques
        self.scrape_challenges()
        
        # Sauvegarder tout
        self.save_all_data()
        self.generate_report()
        
        self.driver.quit()
        print("\n‚úÖ SCRAPING TERMIN√â")
    
    def scrape_page(self, path, page_name):
        """Scraper une page avec Selenium"""
        url = urljoin(self.base_url, path)
        
        try:
            self.driver.get(url)
            time.sleep(3)  # Attendre chargement JS
            
            # Scroll pour lazy loading
            self.scroll_page()
            
            # HTML complet apr√®s JS
            html = self.driver.page_source
            soup = BeautifulSoup(html, 'html.parser')
            
            page_data = {
                'name': page_name,
                'url': url,
                'title': self.driver.title,
                'content': {}
            }
            
            # 1. Extraire TOUT le texte structur√©
            page_data['content']['headings'] = self.extract_headings(soup)
            page_data['content']['paragraphs'] = self.extract_paragraphs(soup)
            page_data['content']['lists'] = self.extract_lists(soup)
            page_data['content']['tables'] = self.extract_tables(soup)
            
            # 2. Extraire √©l√©ments interactifs
            page_data['content']['buttons'] = self.extract_buttons(soup)
            page_data['content']['forms'] = self.extract_forms(soup)
            
            # 3. Extraire m√©dias
            self.extract_links(soup, url)
            self.extract_images(soup, url)
            self.extract_pdfs(soup, url)
            
            # 4. D√©tecter FAQ
            faq_items = self.detect_faq_patterns(soup, url)
            self.all_data['faqs'].extend(faq_items)
            
            self.all_data['pages'].append(page_data)
            self.all_data['metadata']['total_pages'] += 1
            
            print(f"  ‚úÖ {len(page_data['content']['paragraphs'])} paragraphes")
            print(f"  ‚úÖ {len(faq_items)} FAQ d√©tect√©es")
            
        except Exception as e:
            print(f"  ‚ùå Erreur: {e}")
    
    def scroll_page(self):
        """Scroll pour charger contenu dynamique"""
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        
        for _ in range(3):
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
    
    def extract_headings(self, soup):
        """Extraire tous les titres"""
        headings = []
        for level in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            for heading in soup.find_all(level):
                text = heading.get_text(strip=True)
                if len(text) > 3:
                    headings.append({
                        'level': level,
                        'text': text,
                        'id': heading.get('id', '')
                    })
        return headings
    
    def extract_paragraphs(self, soup):
        """Extraire paragraphes avec contexte"""
        paragraphs = []
        for p in soup.find_all('p'):
            text = p.get_text(strip=True)
            if len(text) > 20:
                # Chercher titre parent
                parent_heading = p.find_previous(['h1', 'h2', 'h3'])
                context = parent_heading.get_text(strip=True) if parent_heading else ''
                
                paragraphs.append({
                    'text': text,
                    'context': context,
                    'length': len(text)
                })
        return paragraphs
    
    def extract_lists(self, soup):
        """Extraire listes"""
        lists = []
        for list_elem in soup.find_all(['ul', 'ol']):
            items = [li.get_text(strip=True) for li in list_elem.find_all('li')]
            if items:
                lists.append({
                    'type': list_elem.name,
                    'items': items,
                    'count': len(items)
                })
        return lists
    
    def extract_tables(self, soup):
        """Extraire tableaux"""
        tables = []
        for table in soup.find_all('table'):
            rows = []
            for tr in table.find_all('tr'):
                cells = [td.get_text(strip=True) for td in tr.find_all(['td', 'th'])]
                if cells:
                    rows.append(cells)
            if rows:
                tables.append({
                    'headers': rows[0] if rows else [],
                    'rows': rows[1:] if len(rows) > 1 else [],
                    'size': f"{len(rows)}x{len(rows[0]) if rows else 0}"
                })
        return tables
    
    def extract_buttons(self, soup):
        """Extraire boutons"""
        buttons = []
        for button in soup.find_all(['button', 'a'], class_=re.compile(r'btn|button')):
            buttons.append({
                'text': button.get_text(strip=True),
                'href': button.get('href', ''),
                'onclick': button.get('onclick', '')
            })
        return buttons
    
    def extract_forms(self, soup):
        """Extraire formulaires"""
        forms = []
        for form in soup.find_all('form'):
            fields = []
            for input_elem in form.find_all(['input', 'textarea', 'select']):
                fields.append({
                    'type': input_elem.get('type', 'text'),
                    'name': input_elem.get('name', ''),
                    'placeholder': input_elem.get('placeholder', ''),
                    'required': input_elem.has_attr('required')
                })
            
            forms.append({
                'action': form.get('action', ''),
                'method': form.get('method', 'GET'),
                'fields': fields
            })
        return forms
    
    def extract_links(self, soup, source_url):
        """Extraire tous les liens"""
        for a in soup.find_all('a', href=True):
            href = a['href']
            full_url = urljoin(self.base_url, href)
            
            self.all_data['links'].append({
                'text': a.get_text(strip=True),
                'url': full_url,
                'source': source_url,
                'type': 'internal' if self.base_url in full_url else 'external'
            })
    
    def extract_images(self, soup, source_url):
        """Extraire images"""
        for img in soup.find_all('img'):
            src = img.get('src', '')
            if src:
                full_url = urljoin(self.base_url, src)
                self.all_data['images'].append({
                    'url': full_url,
                    'alt': img.get('alt', ''),
                    'title': img.get('title', ''),
                    'source': source_url
                })
    
    def extract_pdfs(self, soup, source_url):
        """Extraire PDFs"""
        for a in soup.find_all('a', href=re.compile(r'\.pdf$', re.I)):
            href = a['href']
            full_url = urljoin(self.base_url, href)
            
            self.all_data['pdfs'].append({
                'url': full_url,
                'title': a.get_text(strip=True),
                'source': source_url
            })
            
            # T√©l√©charger PDF
            self.download_pdf(full_url)
    
    def download_pdf(self, url):
        """T√©l√©charger PDF"""
        try:
            filename = os.path.basename(urlparse(url).path)
            filepath = f"temp/pdfs/{filename}"
            
            response = requests.get(url, timeout=30)
            if response.status_code == 200:
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                print(f"    üì• PDF: {filename}")
        except Exception as e:
            print(f"    ‚ùå PDF error: {e}")
    
    def detect_faq_patterns(self, soup, source_url):
        """D√©tecter FAQ avec patterns avanc√©s"""
        faq_items = []
        
        # Pattern 1: Sections FAQ explicites
        faq_sections = soup.find_all(['div', 'section'], class_=re.compile(r'faq|question', re.I))
        for section in faq_sections:
            q_elem = section.find(['h3', 'h4', 'h5', 'strong'])
            a_elem = section.find('p')
            
            if q_elem and a_elem:
                faq_items.append({
                    'question_fr': q_elem.get_text(strip=True),
                    'answer_fr': a_elem.get_text(strip=True),
                    'source': source_url,
                    'confidence': 0.9
                })
        
        # Pattern 2: Questions commen√ßant par mots-cl√©s
        question_words = ['comment', 'quoi', 'qui', 'o√π', 'quand', 'pourquoi', 'quel']
        for heading in soup.find_all(['h2', 'h3', 'h4']):
            text = heading.get_text(strip=True).lower()
            if any(text.startswith(word) for word in question_words) and '?' in text:
                # Chercher r√©ponse apr√®s
                next_p = heading.find_next('p')
                if next_p:
                    faq_items.append({
                        'question_fr': heading.get_text(strip=True),
                        'answer_fr': next_p.get_text(strip=True),
                        'source': source_url,
                        'confidence': 0.7
                    })
        
        return faq_items
    
    def scrape_challenges(self):
        """Scraper d√©fis sp√©cifiques"""
        print("\nüìä Scraping d√©fis...")
        
        try:
            self.driver.get(f"{self.base_url}/inscription/defis/liste")
            time.sleep(3)
            
            # Chercher cartes de d√©fis
            challenge_cards = self.driver.find_elements(By.CSS_SELECTOR, '.defi, .challenge, .card')
            
            for card in challenge_cards:
                try:
                    title = card.find_element(By.TAG_NAME, 'h3').text
                    description = card.find_element(By.TAG_NAME, 'p').text
                    
                    self.all_data['challenges'].append({
                        'title': title,
                        'description': description
                    })
                except:
                    continue
            
            print(f"  ‚úÖ {len(self.all_data['challenges'])} d√©fis extraits")
            
        except Exception as e:
            print(f"  ‚ùå Erreur d√©fis: {e}")
    
    def save_all_data(self):
        """Sauvegarder toutes les donn√©es"""
        print("\nüíæ Sauvegarde donn√©es...")
        
        # Sauvegarder JSON complet
        with open('temp/complete_scraped_data.json', 'w', encoding='utf-8') as f:
            json.dump(self.all_data, f, ensure_ascii=False, indent=2)
        
        print(f"  ‚úÖ temp/complete_scraped_data.json")
    
    def generate_report(self):
        """G√©n√©rer rapport"""
        print("\nüìä RAPPORT DE SCRAPING")
        print("-" * 80)
        print(f"Pages scrap√©es:        {self.all_data['metadata']['total_pages']}")
        print(f"FAQ d√©tect√©es:         {len(self.all_data['faqs'])}")
        print(f"D√©fis extraits:        {len(self.all_data['challenges'])}")
        print(f"Liens trouv√©s:         {len(self.all_data['links'])}")
        print(f"Images trouv√©es:       {len(self.all_data['images'])}")
        print(f"PDFs trouv√©s:          {len(self.all_data['pdfs'])}")
        print("-" * 80)


if __name__ == "__main__":
    scraper = AdvancedScraper()
    scraper.scrape_complete_site()
FICHIER: data-collection/02_pdf_extractor.py
python
"""
Extraction texte et tableaux depuis PDFs
"""

import pdfplumber
import os
import json
from tqdm import tqdm

class PDFExtractor:
    def __init__(self):
        self.pdf_folder = 'temp/pdfs'
        self.extracted_data = []
    
    def extract_all_pdfs(self):
        """Extraire tous les PDFs"""
        print("="*80)
        print("üìÑ EXTRACTION PDFs")
        print("="*80)
        
        pdf_files = [f for f in os.listdir(self.pdf_folder) if f.endswith('.pdf')]
        
        for pdf_file in tqdm(pdf_files):
            filepath = os.path.join(self.pdf_folder, pdf_file)
            data = self.extract_pdf(filepath)
            self.extracted_data.append({
                'filename': pdf_file,
                'data': data
            })
        
        # Sauvegarder
        with open('temp/pdf_extracted_data.json', 'w', encoding='utf-8') as f:
            json.dump(self.extracted_data, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úÖ {len(pdf_files)} PDFs trait√©s")
    
    def extract_pdf(self, filepath):
        """Extraire un PDF"""
        extracted = {'pages': [], 'tables': []}
        
        try:
            with pdfplumber.open(filepath) as pdf:
                for page in pdf.pages:
                    # Texte
                    text = page.extract_text()
                    if text:
                        extracted['pages'].append(text)
                    
                    # Tableaux
                    tables = page.extract_tables()
                    for table in tables:
                        extracted['tables'].append(table)
        
        except Exception as e:
            print(f"Erreur {filepath}: {e}")
        
        return extracted


if __name__ == "__main__":
    extractor = PDFExtractor()
    extractor.extract_all_pdfs()
FICHIER: data-collection/03_data_cleaner.py
python
"""
Nettoyage et structuration avanc√©e des donn√©es
"""

import json
import re
import pandas as pd
from difflib import SequenceMatcher
from collections import Counter

class DataCleaner:
    def __init__(self):
        self.cleaned_data = {
            'faqs': [],
            'categories': {},
            'keywords': []
        }
    
    def clean_all(self):
        """Pipeline complet de nettoyage"""
        print("="*80)
        print("üßπ NETTOYAGE DONN√âES")
        print("="*80)
        
        # 1. Charger donn√©es
        with open('temp/complete_scraped_data.json', 'r', encoding='utf-8') as f:
            scraped_data = json.load(f)
        
        # 2. Extraire FAQ depuis toutes les sources
        all_faqs = []
        
        # FAQ d√©tect√©es
        all_faqs.extend(scraped_data['faqs'])
        
        # FAQ depuis pages
        for page in scraped_data['pages']:
            faqs = self.extract_faqs_from_page(page)
            all_faqs.extend(faqs)
        
        # FAQ depuis PDFs
        try:
            with open('temp/pdf_extracted_data.json', 'r', encoding='utf-8') as f:
                pdf_data = json.load(f)
                for pdf in pdf_data:
                    faqs = self.extract_faqs_from_pdf(pdf)
                    all_faqs.extend(faqs)
        except FileNotFoundError:
            pass
        
        print(f"üìä {len(all_faqs)} FAQ brutes collect√©es")
        
        # 3. Nettoyer textes
        cleaned_faqs = [self.clean_faq(faq) for faq in all_faqs]
        
        # 4. D√©dupliquer
        unique_faqs = self.deduplicate(cleaned_faqs)
        print(f"‚úÖ {len(unique_faqs)} FAQ uniques")
        
        # 5. Cat√©goriser
        categorized_faqs = self.categorize_faqs(unique_faqs)
        
        # 6. Enrichir
        enriched_faqs = self.enrich_faqs(categorized_faqs)
        
        # 7. Sauvegarder
        self.save_clean_data(enriched_faqs)
        
        print(f"‚úÖ Donn√©es nettoy√©es sauvegard√©es")
    
    def extract_faqs_from_page(self, page):
        """Extraire FAQ depuis structure page"""
        faqs = []
        
        # Depuis headings + paragraphes
        headings = page['content'].get('headings', [])
        paragraphs = page['content'].get('paragraphs', [])
        
        for i, heading in enumerate(headings):
            if heading['level'] in ['h2', 'h3']:
                # Chercher r√©ponse dans paragraphes suivants
                for para in paragraphs:
                    if para.get('context') == heading['text']:
                        faqs.append({
                            'question_fr': heading['text'],
                            'answer_fr': para['text'],
                            'source': page['url']
                        })
                        break
        
        return faqs
    
    def extract_faqs_from_pdf(self, pdf_data):
        """Extraire FAQ depuis PDF"""
        faqs = []
        
        for page_text in pdf_data['data'].get('pages', []):
            # D√©tecter patterns Q&A
            lines = page_text.split('\n')
            
            for i, line in enumerate(lines):
                if re.match(r'^(Q:|Question|Comment|Quoi|Qui)', line, re.I):
                    question = line.strip()
                    
                    # R√©ponse = lignes suivantes
                    answer_lines = []
                    for j in range(i+1, min(i+5, len(lines))):
                        if lines[j].strip():
                            answer_lines.append(lines[j])
                        else:
                            break
                    
                    if answer_lines:
                        faqs.append({
                            'question_fr': question,
                            'answer_fr': ' '.join(answer_lines),
                            'source': 'pdf'
                        })
        
        return faqs
    
    def clean_faq(self, faq):
        """Nettoyer une FAQ"""
        cleaned = {}
        
        for key in ['question_fr', 'answer_fr']:
            text = faq.get(key, '')
            
            # Nettoyer
            text = re.sub(r'\s+', ' ', text)  # Espaces multiples
            text = re.sub(r'[^\w\s\'\"-.,!?()√†√©√®√™√¥√π√ª√ß]', '', text)  # Caract√®res sp√©ciaux
            text = text.strip()
            
            # Limiter longueur
            if key == 'question_fr':
                text = text[:300]
            else:
                text = text[:800]
            
            cleaned[key] = text
        
        cleaned['source'] = faq.get('source', 'unknown')
        return cleaned
    
    def deduplicate(self, faqs):
        """Supprimer doublons avec similarit√©"""
        unique = []
        seen_questions = []
        
        for faq in faqs:
            question = faq.get('question_fr', '')
            
            if len(question) < 15:
                continue
            
            # V√©rifier similarit√©
            is_duplicate = False
            for seen_q in seen_questions:
                similarity = SequenceMatcher(None, question.lower(), seen_q.lower()).ratio()
                if similarity > 0.85:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique.append(faq)
                seen_questions.append(question)
        
        return unique
    
    def categorize_faqs(self, faqs):
        """Cat√©goriser automatiquement"""
        categories = {
            'inscription': ['inscription', 'inscrire', '√©quipe', 'participer', 'rejoindre'],
            'defis': ['d√©fi', 'challenge', '√©preuve', 'concours'],
            'reglement': ['r√®gle', 'r√®glement', 'modalit√©', 'condition'],
            'organisation': ['organiser', 'd√©roulement', 'horaire', 'planning'],
            'technique': ['technologie', 'outil', 'framework', 'code', 'd√©veloppement'],
            'evaluation': ['jury', '√©valuation', 'crit√®re', 'notation', 'prix']
        }
        
        for faq in faqs:
            question = faq['question_fr'].lower()
            
            # Trouver cat√©gorie
            scores = {}
            for cat, keywords in categories.items():
                score = sum(1 for kw in keywords if kw in question)
                scores[cat] = score
            
            best_cat = max(scores, key=scores.get) if max(scores.values()) > 0 else 'general'
            faq['category'] = best_cat
        
        return faqs
    
    def enrich_faqs(self, faqs):
        """Enrichir avec m√©tadonn√©es"""
        for i, faq in enumerate(faqs, start=1):
            faq['id'] = i
            faq['question_ar'] = ''  # √Ä compl√©ter avec traduction
            faq['answer_ar'] = ''
            faq['keywords'] = self.extract_keywords(faq['question_fr'])
            faq['offline_priority'] = self.calculate_priority(faq)
        
        return faqs
    
    def extract_keywords(self, text):
        """Extraire mots-cl√©s"""
        stop_words = {
            'le', 'la', 'les', 'un', 'une', 'des', 'et', 'ou', 'mais',
            'pour', 'dans', 'sur', 'avec', 'par', 'comment', 'quoi', 'quel'
        }
        
        words = re.findall(r'\b[a-z√†√©√®√™√¥√π√ª]{4,}\b', text.lower())
        keywords = [w for w in words if w not in stop_words]
        
        # Garder plus fr√©quents
        counter = Counter(keywords)
        return [word for word, count in counter.most_common(8)]
    
    def calculate_priority(self, faq):
        """Calculer priorit√© offline"""
        # Questions fr√©quentes = priorit√© haute
        high_priority_keywords = ['inscription', 'participer', '√©quipe', 'horaire', 'r√®gle']
        
        question = faq['question_fr'].lower()
        
        for kw in high_priority_keywords:
            if kw in question:
                return 10
        
        return 5
    
    def save_clean_data(self, faqs):
        """Sauvegarder donn√©es nettoy√©es"""
        output = {
            'version': '1.0',
            'last_updated': '2025-12-05',
            'total_faqs': len(faqs),
            'faqs': faqs,
            'categories': [
                {'id': 'inscription', 'name_fr': 'Inscription', 'name_ar': 'ÿßŸÑÿ™ÿ≥ÿ¨ŸäŸÑ'},
                {'id': 'defis', 'name_fr': 'D√©fis', 'name_ar': 'ÿßŸÑÿ™ÿ≠ÿØŸäÿßÿ™'},
                {'id': 'reglement', 'name_fr': 'R√®glement', 'name_ar': 'ÿßŸÑŸÑŸàÿßÿ¶ÿ≠'},
                {'id': 'organisation', 'name_fr': 'Organisation', 'name_ar': 'ÿßŸÑÿ™ŸÜÿ∏ŸäŸÖ'},
                {'id': 'technique', 'name_fr': 'Technique', 'name_ar': 'ÿßŸÑÿ™ŸÇŸÜŸäÿ©'},
                {'id': 'evaluation', 'name_fr': '√âvaluation', 'name_ar': 'ÿßŸÑÿ™ŸÇŸäŸäŸÖ'}
            ]
        }
        
        with open('../frontend/public/data/faqs.json', 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    cleaner = DataCleaner()
    cleaner.clean_all()
SUITE DANS PROCHAINE R√âPONSE (limite caract√®res atteinte)...

Voulez-vous que je continue avec:

G√©n√©ration embeddings (05)

Quantification mod√®le (06)

Code frontend React complet

Tests et d√©ploiement
?

G√©n√©ration embeddings (05)
Quantification mod√®le (06)
Code frontend React complet

üì¶ SUITE DU PROJET - PARTIE 2
FICHIER: data-collection/05_embeddings_creator.py
python
"""
G√©n√©ration embeddings multilingues optimis√©s
Pour RAG offline/online
"""

from sentence_transformers import SentenceTransformer
import json
import numpy as np
from tqdm import tqdm
import os

class EmbeddingsCreator:
    def __init__(self):
        print("="*80)
        print("üßÆ G√âN√âRATION EMBEDDINGS MULTILINGUES")
        print("="*80)
        
        # Mod√®le l√©ger multilingue FR/AR
        print("üì• Chargement mod√®le...")
        self.model = SentenceTransformer(
            'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'
        )
        print(f"‚úÖ Mod√®le charg√©: {self.model.get_sentence_embedding_dimension()} dimensions")
        
        self.embeddings_data = []
    
    def create_all_embeddings(self):
        """Cr√©er embeddings pour toutes les FAQ"""
        
        # Charger FAQ nettoy√©es
        with open('../frontend/public/data/faqs.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        faqs = data['faqs']
        print(f"\nüìä Traitement de {len(faqs)} FAQ...")
        
        # G√©n√©rer embeddings
        for faq in tqdm(faqs, desc="G√©n√©ration embeddings"):
            embedding = self.create_faq_embedding(faq)
            
            self.embeddings_data.append({
                'id': faq['id'],
                'embedding': embedding.tolist(),
                'category': faq['category']
            })
        
        # Sauvegarder
        self.save_embeddings()
        
        # Statistiques
        self.generate_stats()
    
    def create_faq_embedding(self, faq):
        """Cr√©er embedding pour une FAQ"""
        # Combiner question + keywords pour meilleur matching
        text_parts = [
            faq['question_fr'],
            faq.get('question_ar', ''),
            ' '.join(faq['keywords'])
        ]
        
        combined_text = ' '.join([t for t in text_parts if t])
        
        # G√©n√©rer embedding normalis√©
        embedding = self.model.encode(
            combined_text,
            normalize_embeddings=True,
            show_progress_bar=False
        )
        
        return embedding
    
    def save_embeddings(self):
        """Sauvegarder embeddings"""
        print("\nüíæ Sauvegarde embeddings...")
        
        # Version compl√®te (pour backend)
        output_full = {
            'version': '1.0',
            'model': 'paraphrase-multilingual-MiniLM-L12-v2',
            'dimension': 384,
            'total_embeddings': len(self.embeddings_data),
            'embeddings': self.embeddings_data
        }
        
        with open('../frontend/public/data/embeddings.json', 'w') as f:
            json.dump(output_full, f, indent=2)
        
        file_size = os.path.getsize('../frontend/public/data/embeddings.json')
        print(f"‚úÖ Embeddings sauvegard√©s: {file_size / 1024:.1f} KB")
        
        # Version compress√©e (pour offline)
        self.create_compressed_version()
    
    def create_compressed_version(self):
        """Cr√©er version compress√©e pour offline"""
        print("\nüóúÔ∏è  Cr√©ation version compress√©e...")
        
        # Quantifier embeddings en int8 pour r√©duire taille
        compressed = []
        
        for emb_data in self.embeddings_data:
            embedding = np.array(emb_data['embedding'])
            
            # Quantifier [-1, 1] -> [-127, 127]
            quantized = (embedding * 127).astype(np.int8)
            
            compressed.append({
                'id': emb_data['id'],
                'embedding': quantized.tolist(),
                'category': emb_data['category']
            })
        
        output_compressed = {
            'version': '1.0',
            'format': 'int8_quantized',
            'dimension': 384,
            'embeddings': compressed
        }
        
        with open('../frontend/public/data/embeddings_compressed.json', 'w') as f:
            json.dump(output_compressed, f)
        
        compressed_size = os.path.getsize('../frontend/public/data/embeddings_compressed.json')
        print(f"‚úÖ Version compress√©e: {compressed_size / 1024:.1f} KB")
    
    def generate_stats(self):
        """G√©n√©rer statistiques"""
        print("\nüìä STATISTIQUES EMBEDDINGS")
        print("-" * 80)
        print(f"Total embeddings:      {len(self.embeddings_data)}")
        print(f"Dimension:             384")
        print(f"Mod√®le:                paraphrase-multilingual-MiniLM-L12-v2")
        
        # Stats par cat√©gorie
        categories = {}
        for emb in self.embeddings_data:
            cat = emb['category']
            categories[cat] = categories.get(cat, 0) + 1
        
        print(f"\nR√©partition par cat√©gorie:")
        for cat, count in sorted(categories.items()):
            print(f"  {cat:20} {count:3} embeddings")
        print("-" * 80)


if __name__ == "__main__":
    creator = EmbeddingsCreator()
    creator.create_all_embeddings()
FICHIER: data-collection/06_model_quantizer.py
python
"""
Quantification mod√®le ONNX pour d√©ploiement low-cost
R√©duit taille de 70-80% avec perte minimale de pr√©cision
"""

from transformers import AutoTokenizer, AutoModelForCausalLM
from optimum.onnxruntime import ORTModelForCausalLM, ORTQuantizer
from optimum.onnxruntime.configuration import AutoQuantizationConfig
import torch
import os

class ModelQuantizer:
    def __init__(self):
        print("="*80)
        print("üîß QUANTIFICATION MOD√àLE ONNX")
        print("="*80)
        
        self.models_dir = '../frontend/public/models'
        os.makedirs(self.models_dir, exist_ok=True)
    
    def quantize_model(self):
        """Pipeline complet de quantification"""
        
        # Choisir mod√®le l√©ger
        model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"  # Ultra l√©ger
        
        print(f"\nüì• T√©l√©chargement mod√®le: {model_name}")
        print("   ‚ö†Ô∏è  Peut prendre 5-10 minutes...")
        
        try:
            # √âtape 1: Charger mod√®le PyTorch
            print("\n1Ô∏è‚É£  Chargement mod√®le PyTorch...")
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float16,
                low_cpu_mem_usage=True
            )
            
            print(f"‚úÖ Mod√®le charg√©: {sum(p.numel() for p in model.parameters())/1e6:.1f}M param√®tres")
            
            # √âtape 2: Export ONNX
            print("\n2Ô∏è‚É£  Export vers ONNX...")
            ort_model = ORTModelForCausalLM.from_pretrained(
                model_name,
                export=True
            )
            
            # Sauvegarder ONNX non-quantifi√©
            onnx_path = f"{self.models_dir}/model_fp32.onnx"
            ort_model.save_pretrained(self.models_dir)
            print(f"‚úÖ ONNX export√©")
            
            # √âtape 3: Quantification dynamique
            print("\n3Ô∏è‚É£  Quantification dynamique (int8)...")
            quantizer = ORTQuantizer.from_pretrained(ort_model)
            
            qconfig = AutoQuantizationConfig.avx512_vnni(
                is_static=False,
                per_channel=True
            )
            
            quantized_path = f"{self.models_dir}/model_quantized"
            quantizer.quantize(
                save_dir=quantized_path,
                quantization_config=qconfig
            )
            
            print(f"‚úÖ Mod√®le quantifi√© sauvegard√©")
            
            # √âtape 4: Statistiques
            self.compare_models()
            
            print("\n‚úÖ QUANTIFICATION TERMIN√âE")
            
        except Exception as e:
            print(f"\n‚ùå Erreur: {e}")
            print("\nüí° SOLUTION ALTERNATIVE: Utiliser mod√®le pr√©-quantifi√©")
            self.download_prequantized_model()
    
    def download_prequantized_model(self):
        """T√©l√©charger mod√®le d√©j√† quantifi√©"""
        print("\nüì• T√©l√©chargement mod√®le pr√©-quantifi√©...")
        
        # Utiliser mod√®le plus petit d√©j√† optimis√©
        model_name = "Xenova/LaMini-Flan-T5-783M"
        
        try:
            from transformers import pipeline
            
            # T√©l√©charger via transformers.js compatible
            print("   Utilisation de mod√®le optimis√© navigateur...")
            
            # Cr√©er fichier config
            config = {
                'model_name': model_name,
                'type': 'text-generation',
                'quantized': True,
                'size_mb': 300,
                'parameters': '783M',
                'usage': 'offline-hybrid'
            }
            
            with open(f"{self.models_dir}/model_config.json", 'w') as f:
                import json
                json.dump(config, f, indent=2)
            
            print(f"‚úÖ Configuration mod√®le cr√©√©e")
            print(f"   Mod√®le: {model_name}")
            print(f"   Taille: ~300MB")
            
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
    
    def compare_models(self):
        """Comparer tailles mod√®les"""
        print("\nüìä COMPARAISON MOD√àLES")
        print("-" * 80)
        
        if os.path.exists(f"{self.models_dir}/model_fp32.onnx"):
            size_fp32 = os.path.getsize(f"{self.models_dir}/model_fp32.onnx")
            print(f"FP32 (original):       {size_fp32 / 1e6:.1f} MB")
        
        if os.path.exists(f"{self.models_dir}/model_quantized"):
            # Calculer taille dossier
            size_quant = sum(
                os.path.getsize(os.path.join(dirpath, filename))
                for dirpath, dirnames, filenames in os.walk(f"{self.models_dir}/model_quantized")
                for filename in filenames
            )
            print(f"INT8 (quantifi√©):      {size_quant / 1e6:.1f} MB")
            
            if os.path.exists(f"{self.models_dir}/model_fp32.onnx"):
                reduction = (1 - size_quant / size_fp32) * 100
                print(f"R√©duction:             {reduction:.1f}%")
        
        print("-" * 80)


if __name__ == "__main__":
    quantizer = ModelQuantizer()
    quantizer.quantize_model()
üé® FRONTEND REACT COMPLET
FICHIER: frontend/package.json
json
{
  "name": "assistant-ia-lowcost",
  "version": "1.0.0",
  "description": "Assistant IA Low-Cost pour Nuit de l'Info 2025 - FST Nouakchott",
  "private": true,
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-scripts": "5.0.1",
    "i18next": "^23.7.8",
    "react-i18next": "^13.5.0",
    "idb": "^8.0.0",
    "@xenova/transformers": "^2.10.0",
    "onnxruntime-web": "^1.16.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject",
    "analyze": "source-map-explorer 'build/static/js/*.js'"
  },
  "eslintConfig": {
    "extends": ["react-app"]
  },
  "browserslist": {
    "production": [">0.2%", "not dead", "not op_mini all"],
    "development": ["last 1 chrome version", "last 1 firefox version", "last 1 safari version"]
  },
  "devDependencies": {
    "source-map-explorer": "^2.5.3"
  }
}
FICHIER: frontend/src/services/ml/ONNXRunner.js
javascript
/**
 * Ex√©cution mod√®le ONNX dans le navigateur
 * Utilise WebAssembly pour performance
 */

import * as ort from 'onnxruntime-web';

class ONNXRunner {
  constructor() {
    this.session = null;
    this.isLoaded = false;
    this.modelPath = '/models/model_quantized.onnx';
  }

  /**
   * Charger mod√®le ONNX (lazy loading)
   */
  async loadModel() {
    if (this.isLoaded) return;

    try {
      console.log('ü§ñ Chargement mod√®le ONNX...');
      
      // Configuration optimis√©e
      ort.env.wasm.numThreads = 1;
      ort.env.wasm.simd = true;
      
      this.session = await ort.InferenceSession.create(this.modelPath, {
        executionProviders: ['wasm'],
        graphOptimizationLevel: 'all'
      });
      
      this.isLoaded = true;
      console.log('‚úÖ Mod√®le ONNX charg√©');
      
    } catch (error) {
      console.warn('‚ùå Erreur chargement ONNX:', error);
      console.log('üí° Utilisation fallback sans mod√®le');
      this.isLoaded = false;
    }
  }

  /**
   * Ex√©cuter inf√©rence
   */
  async run(inputText) {
    if (!this.isLoaded) {
      await this.loadModel();
    }

    if (!this.session) {
      throw new Error('Mod√®le non disponible');
    }

    try {
      // Pr√©parer input (√† adapter selon votre mod√®le)
      const inputTensor = this.prepareInput(inputText);
      
      const feeds = { input: inputTensor };
      const results = await this.session.run(feeds);
      
      return this.processOutput(results);
      
    } catch (error) {
      console.error('Erreur inf√©rence:', error);
      throw error;
    }
  }

  /**
   * Pr√©parer input pour mod√®le
   */
  prepareInput(text) {
    // Tokenization simple (√† adapter)
    const maxLength = 128;
    const tokens = text.split(' ').slice(0, maxLength);
    
    // Convertir en tensor (exemple simplifi√©)
    const inputIds = new Float32Array(maxLength);
    tokens.forEach((token, i) => {
      inputIds[i] = this.hashToken(token);
    });
    
    return new ort.Tensor('float32', inputIds, [1, maxLength]);
  }

  /**
   * Hash simple pour tokens
   */
  hashToken(token) {
    let hash = 0;
    for (let i = 0; i < token.length; i++) {
      hash = ((hash << 5) - hash) + token.charCodeAt(i);
      hash = hash & hash;
    }
    return Math.abs(hash) % 50000;
  }

  /**
   * Traiter sortie mod√®le
   */
  processOutput(results) {
    const outputTensor = results.output;
    const outputData = outputTensor.data;
    
    // Traitement d√©pend de votre mod√®le
    return {
      logits: Array.from(outputData),
      prediction: outputData[0]
    };
  }

  /**
   * Lib√©rer ressources
   */
  async dispose() {
    if (this.session) {
      await this.session.release();
      this.session = null;
      this.isLoaded = false;
    }
  }
}

export default new ONNXRunner();
FICHIER: frontend/src/services/ml/RAGService.js
javascript
/**
 * Retrieval-Augmented Generation (RAG)
 * Recherche s√©mantique dans FAQ avec embeddings
 */

import { initDB } from '../storage/IndexedDBManager';

class RAGService {
  constructor() {
    this.embeddings = null;
    this.faqs = null;
  }

  /**
   * Initialiser RAG avec donn√©es
   */
  async initialize() {
    const db = await initDB();
    
    this.embeddings = await db.getAll('embeddings');
    this.faqs = await db.getAll('faqs');
    
    console.log(`‚úÖ RAG initialis√©: ${this.embeddings.length} embeddings`);
  }

  /**
   * Rechercher FAQ pertinentes
   */
  async retrieveRelevant(query, topK = 3) {
    if (!this.embeddings || !this.faqs) {
      await this.initialize();
    }

    // Cr√©er embedding de la requ√™te
    const queryEmbedding = this.createQueryEmbedding(query);
    
    // Calculer similarit√©s
    const similarities = this.embeddings.map(embObj => {
      const similarity = this.cosineSimilarity(
        queryEmbedding,
        embObj.embedding
      );
      
      return {
        id: embObj.id,
        similarity: similarity
      };
    });

    // Trier par similarit√©
    similarities.sort((a, b) => b.similarity - a.similarity);
    
    // R√©cup√©rer top K FAQ
    const topResults = similarities.slice(0, topK);
    
    const relevantFAQs = topResults.map(result => {
      const faq = this.faqs.find(f => f.id === result.id);
      return {
        ...faq,
        similarity: result.similarity,
        relevance: this.getRelevanceLevel(result.similarity)
      };
    });

    return relevantFAQs;
  }

  /**
   * Cr√©er embedding simple pour requ√™te
   * Version lightweight sans mod√®le ML
   */
  createQueryEmbedding(text) {
    const dimension = 384;
    const embedding = new Array(dimension).fill(0);
    
    // Tokenization
    const tokens = text.toLowerCase().split(/\s+/);
    
    // TF-IDF simplifi√© + hashing
    tokens.forEach((token, idx) => {
      const hash = this.hashString(token);
      const position = Math.abs(hash) % dimension;
      
      // TF
      embedding[position] += 1;
      
      // Position encoding
      const posWeight = 1 / (idx + 1);
      embedding[(position + 1) % dimension] += posWeight;
    });

    // Normalisation L2
    const magnitude = Math.sqrt(
      embedding.reduce((sum, val) => sum + val * val, 0)
    );
    
    return embedding.map(val => val / (magnitude || 1));
  }

  /**
   * Hash string vers nombre
   */
  hashString(str) {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash;
    }
    return hash;
  }

  /**
   * Similarit√© cosinus
   */
  cosineSimilarity(vecA, vecB) {
    if (vecA.length !== vecB.length) {
      throw new Error('Vecteurs de dimensions diff√©rentes');
    }

    let dotProduct = 0;
    let magA = 0;
    let magB = 0;

    for (let i = 0; i < vecA.length; i++) {
      dotProduct += vecA[i] * vecB[i];
      magA += vecA[i] * vecA[i];
      magB += vecB[i] * vecB[i];
    }

    magA = Math.sqrt(magA);
    magB = Math.sqrt(magB);

    if (magA === 0 || magB === 0) return 0;

    return dotProduct / (magA * magB);
  }

  /**
   * Niveau de pertinence
   */
  getRelevanceLevel(similarity) {
    if (similarity >= 0.8) return 'high';
    if (similarity >= 0.5) return 'medium';
    return 'low';
  }

  /**
   * G√©n√©rer contexte pour LLM
   */
  buildContext(faqs, query, language = 'fr') {
    const questionKey = `question_${language}`;
    const answerKey = `answer_${language}`;

    const context = faqs.map((faq, idx) => {
      const question = faq[questionKey] || faq.question_fr;
      const answer = faq[answerKey] || faq.answer_fr;
      
      return `[FAQ ${idx + 1}] Q: ${question}\nR: ${answer}`;
    }).join('\n\n');

    return `Contexte:\n${context}\n\nQuestion utilisateur: ${query}\n\nR√©ponse:`;
  }
}

export default new RAGService();
FICHIER: frontend/src/services/aiEngine/AIService.js
javascript
/**
 * Service IA principal - Orchestrateur des 3 modes
 * - Mode 1: OFFLINE (recherche keywords)
 * - Mode 2: HYBRIDE (RAG + embeddings)
 * - Mode 3: ONLINE (API backend)
 */

import OfflineEngine from './OfflineEngine';
import HybridEngine from './HybridEngine';
import OnlineEngine from './OnlineEngine';

class AIService {
  constructor() {
    this.offlineEngine = OfflineEngine;
    this.hybridEngine = HybridEngine;
    this.onlineEngine = OnlineEngine;
    
    this.currentMode = null;
  }

  /**
   * D√©tecter qualit√© de connexion
   */
  getConnectionQuality() {
    // Offline
    if (!navigator.onLine) {
      return 'offline';
    }

    // V√©rifier type connexion
    const connection = navigator.connection 
      || navigator.mozConnection 
      || navigator.webkitConnection;

    if (!connection) {
      return 'online'; // Assume online si pas d'API
    }

    const effectiveType = connection.effectiveType;
    const downlink = connection.downlink; // Mbps

    // Classification
    if (effectiveType === '4g' && downlink > 10) {
      return 'high';
    } else if (effectiveType === '4g' || effectiveType === '3g') {
      return 'medium';
    } else if (effectiveType === '2g' || downlink < 1) {
      return 'low';
    }

    return 'online';
  }

  /**
   * Obtenir r√©ponse IA (point d'entr√©e principal)
   */
  async getResponse(query, language = 'fr') {
    const quality = this.getConnectionQuality();
    
    console.log(`üîÑ Mode: ${quality} | Query: "${query.substring(0, 50)}..."`);

    let response;

    try {
      switch (quality) {
        case 'offline':
          this.currentMode = 'offline';
          response = await this.offlineEngine.process(query, language);
          break;

        case 'low':
        case 'medium':
          this.currentMode = 'hybrid';
          response = await this.hybridEngine.process(query, language);
          break;

        case 'high':
        case 'online':
          this.currentMode = 'online';
          response = await this.onlineEngine.process(query, language);
          break;

        default:
          this.currentMode = 'hybrid';
          response = await this.hybridEngine.process(query, language);
      }

      return {
        ...response,
        mode: this.currentMode,
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      console.error('‚ùå Erreur AI Service:', error);
      
      // Fallback vers mode offline
      if (this.currentMode !== 'offline') {
        console.log('üîÑ Fallback vers mode offline');
        return this.offlineEngine.process(query, language);
      }

      throw error;
    }
  }

  /**
   * Obtenir mode actuel
   */
  getCurrentMode() {
    return this.currentMode || this.getConnectionQuality();
  }

  /**
   * Forcer un mode sp√©cifique (pour tests)
   */
  async forceMode(mode, query, language = 'fr') {
    switch (mode) {
      case 'offline':
        return this.offlineEngine.process(query, language);
      case 'hybrid':
        return this.hybridEngine.process(query, language);
      case 'online':
        return this.onlineEngine.process(query, language);
      default:
        throw new Error(`Mode invalide: ${mode}`);
    }
  }
}

export default new AIService();
FICHIER: frontend/src/services/aiEngine/OfflineEngine.js
javascript
/**
 * Mode OFFLINE - Recherche par mots-cl√©s
 * Performance: < 200ms
 * Utilise uniquement IndexedDB
 */

import { searchByKeywords } from '../storage/IndexedDBManager';

class OfflineEngine {
  /**
   * Traiter requ√™te en mode offline
   */
  async process(query, language = 'fr') {
    console.log('üî¥ Mode OFFLINE activ√©');

    const startTime = performance.now();

    try {
      // Recherche par keywords dans IndexedDB
      const results = await searchByKeywords(query);

      const endTime = performance.now();
      const responseTime = Math.round(endTime - startTime);

      if (results.length === 0) {
        return {
          answer: this.getNoResultsMessage(language),
          sources: [],
          confidence: 0,
          responseTime,
          method: 'keyword_fallback'
        };
      }

      // Meilleur r√©sultat
      const bestMatch = results[0];
      const answerKey = `answer_${language}`;
      const answer = bestMatch[answerKey] || bestMatch.answer_fr;

      return {
        answer,
        sources: results.slice(0, 3),
        confidence: this.calculateConfidence(query, bestMatch),
        responseTime,
        method: 'keyword_search'
      };

    } catch (error) {
      console.error('Erreur mode offline:', error);
      
      return {
        answer: this.getErrorMessage(language),
        sources: [],
        confidence: 0,
        responseTime: 0,
        method: 'error'
      };
    }
  }

  /**
   * Calculer confiance bas√©e sur matching keywords
   */
  calculateConfidence(query, faq) {
    const queryWords = query.toLowerCase().split(/\s+/);
    const faqKeywords = faq.keywords.map(k => k.toLowerCase());

    const matches = queryWords.filter(word => 
      faqKeywords.some(kw => kw.includes(word) || word.includes(kw))
    );

    const confidence = matches.length / Math.max(queryWords.length, 1);

    return Math.min(confidence * 0.8, 0.8); // Max 0.8 pour offline
  }

  /**
   * Message aucun r√©sultat
   */
  getNoResultsMessage(language) {
    const messages = {
      fr: "D√©sol√©, aucune r√©ponse trouv√©e hors ligne pour cette question. Essayez de reformuler ou connectez-vous pour plus d'aide.",
      ar: "ÿπÿ∞ÿ±ÿßÿå ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ÿ•ÿ¨ÿßÿ®ÿ© ÿØŸàŸÜ ÿßÿ™ÿµÿßŸÑ ŸÑŸáÿ∞ÿß ÿßŸÑÿ≥ÿ§ÿßŸÑ. ÿ≠ÿßŸàŸÑ ÿ•ÿπÿßÿØÿ© ÿßŸÑÿµŸäÿßÿ∫ÿ© ÿ£Ÿà ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ©."
    };

    return messages[language] || messages.fr;
  }

  /**
   * Message erreur
   */
  getErrorMessage(language) {
    const messages = {
      fr: "Une erreur s'est produite. Veuillez r√©essayer.",
      ar: "ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ."
    };

    return messages[language] || messages.fr;
  }
}

export default new OfflineEngine();
FICHIER: frontend/src/services/aiEngine/HybridEngine.js
javascript
/**
 * Mode HYBRIDE - RAG avec embeddings locaux
 * Performance: < 3s
 * Utilise RAG + similarit√© s√©mantique
 */

import RAGService from '../ml/RAGService';
import ONNXRunner from '../ml/ONNXRunner';

class HybridEngine {
  constructor() {
    this.useONNX = false; // Activer si mod√®le ONNX disponible
  }

  /**
   * Traiter requ√™te en mode hybride
   */
  async process(query, language = 'fr') {
    console.log('üü° Mode HYBRIDE activ√©');

    const startTime = performance.now();

    try {
      // √âtape 1: Retrieval avec RAG
      const relevantFAQs = await RAGService.retrieveRelevant(query, 3);

      if (relevantFAQs.length === 0 || relevantFAQs[0].similarity < 0.3) {
        // Fallback offline si pas de r√©sultats pertinents
        const OfflineEngine = (await import('./OfflineEngine')).default;
        return OfflineEngine.process(query, language);
      }

      // √âtape 2: S√©lectionner meilleure r√©ponse
      let answer;
      let method = 'rag_direct';

      if (relevantFAQs[0].similarity >= 0.75) {
        // Similarit√© haute: retour direct
        const answerKey = `answer_${language}`;
        answer = relevantFAQs[0][answerKey] || relevantFAQs[0].answer_fr;
      } else if (this.useONNX) {
        // Similarit√© moyenne: utiliser ONNX pour reformuler
        answer = await this.generateWithONNX(relevantFAQs, query, language);
        method = 'rag_onnx';
      } else {
        // Fallback: meilleure r√©ponse disponible
        const answerKey = `answer_${language}`;
        answer = relevantFAQs[0][answerKey] || relevantFAQs[0].answer_fr;
      }

      const endTime = performance.now();
      const responseTime = Math.round(endTime - startTime);

      return {
        answer,
        sources: relevantFAQs,
        confidence: relevantFAQs[0].similarity,
        responseTime,
        method
      };

    } catch (error) {
      console.error('Erreur mode hybride:', error);
      
      // Fallback offline
      const OfflineEngine = (await import('./OfflineEngine')).default;
      return OfflineEngine.process(query, language);
    }
  }

  /**
   * G√©n√©rer r√©ponse avec mod√®le ONNX
   */
  async generateWithONNX(faqs, query, language) {
    try {
      // Construire prompt
      const context = RAGService.buildContext(faqs, query, language);

      // Ex√©cuter inf√©rence
      const result = await ONNXRunner.run(context);

      // Extraire r√©ponse g√©n√©r√©e
      return this.extractAnswer(result, faqs, language);

    } catch (error) {
      console.error('Erreur ONNX:', error);
      
      // Fallback: meilleure FAQ
      const answerKey = `answer_${language}`;
      return faqs[0][answerKey] || faqs[0].answer_fr;
    }
  }

  /**
   * Extraire r√©ponse depuis sortie mod√®le
   */
  extractAnswer(modelOutput, faqs, language) {
    // Traitement d√©pend du format de sortie
    // Simplifi√© ici
    const answerKey = `answer_${language}`;
    return faqs[0][answerKey] || faqs[0].answer_fr;
  }
}

export default new HybridEngine();
FICHIER: frontend/src/services/aiEngine/OnlineEngine.js
javascript
/**
 * Mode ONLINE - API backend compl√®te
 * Performance: < 1s
 * Utilise backend avec mod√®le complet
 */

import APIService from '../api/APIService';

class OnlineEngine {
  /**
   * Traiter requ√™te en mode online
   */
  async process(query, language = 'fr') {
    console.log('üü¢ Mode ONLINE activ√©');

    const startTime = performance.now();

    try {
      // Appel API backend
      const response = await APIService.chat({
        query,
        language,
        timestamp: Date.now()
      });

      const endTime = performance.now();
      const responseTime = Math.round(endTime - startTime);

      return {
        answer: response.answer,
        sources: response.sources || [],
        confidence: response.confidence || 0.9,
        responseTime,
        method: 'api_backend'
      };

    } catch (error) {
      console.error('‚ùå Erreur API, fallback hybride');
      
      // Fallback hybride
      const HybridEngine = (await import('./HybridEngine')).default;
      return HybridEngine.process(query, language);
    }
  }
}

export default new OnlineEngine();
SUITE DANS PROCHAINE R√âPONSE avec:

Components React (ChatInterface, etc.)

Hooks personnalis√©s

Tests et d√©ploiement

Voulez-vous que je continue ? üöÄ

continue

üé® FRONTEND REACT - PARTIE 3 (COMPONENTS & UI)
FICHIER: frontend/src/services/storage/IndexedDBManager.js
javascript
/**
 * Gestionnaire IndexedDB pour stockage offline
 * G√®re FAQ, embeddings, conversations
 */

import { openDB } from 'idb';

const DB_NAME = 'AssistantIADB';
const DB_VERSION = 1;

/**
 * Initialiser base de donn√©es
 */
export const initDB = async () => {
  return openDB(DB_NAME, DB_VERSION, {
    upgrade(db) {
      // Store FAQ
      if (!db.objectStoreNames.contains('faqs')) {
        const faqStore = db.createObjectStore('faqs', { keyPath: 'id' });
        faqStore.createIndex('category', 'category');
        faqStore.createIndex('keywords', 'keywords', { multiEntry: true });
        faqStore.createIndex('priority', 'offline_priority');
      }

      // Store embeddings
      if (!db.objectStoreNames.contains('embeddings')) {
        const embStore = db.createObjectStore('embeddings', { keyPath: 'id' });
        embStore.createIndex('category', 'category');
      }

      // Store conversations
      if (!db.objectStoreNames.contains('conversations')) {
        const convStore = db.createObjectStore('conversations', {
          keyPath: 'id',
          autoIncrement: true
        });
        convStore.createIndex('timestamp', 'timestamp');
      }

      // Store metadata
      if (!db.objectStoreNames.contains('metadata')) {
        db.createObjectStore('metadata', { keyPath: 'key' });
      }
    }
  });
};

/**
 * Charger donn√©es initiales
 */
export const loadInitialData = async () => {
  console.log('üì• Chargement donn√©es dans IndexedDB...');
  
  const db = await initDB();

  try {
    // V√©rifier si d√©j√† charg√©
    const metadata = await db.get('metadata', 'data_loaded');
    if (metadata && metadata.value) {
      console.log('‚úÖ Donn√©es d√©j√† charg√©es');
      return true;
    }

    // Charger FAQ
    console.log('  üìÑ Chargement FAQ...');
    const faqsResponse = await fetch('/data/faqs.json');
    const faqsData = await faqsResponse.json();

    const tx1 = db.transaction('faqs', 'readwrite');
    for (const faq of faqsData.faqs) {
      await tx1.store.put(faq);
    }
    await tx1.done;
    console.log(`  ‚úÖ ${faqsData.faqs.length} FAQ charg√©es`);

    // Charger embeddings
    console.log('  üßÆ Chargement embeddings...');
    const embResponse = await fetch('/data/embeddings.json');
    const embData = await embResponse.json();

    const tx2 = db.transaction('embeddings', 'readwrite');
    for (const emb of embData.embeddings) {
      await tx2.store.put(emb);
    }
    await tx2.done;
    console.log(`  ‚úÖ ${embData.embeddings.length} embeddings charg√©s`);

    // Marquer comme charg√©
    await db.put('metadata', {
      key: 'data_loaded',
      value: true,
      timestamp: Date.now()
    });

    console.log('‚úÖ Toutes les donn√©es charg√©es');
    return true;

  } catch (error) {
    console.error('‚ùå Erreur chargement donn√©es:', error);
    return false;
  }
};

/**
 * Recherche par keywords (mode offline)
 */
export const searchByKeywords = async (query) => {
  const db = await initDB();
  const allFAQs = await db.getAll('faqs');

  const queryWords = query.toLowerCase()
    .split(/\s+/)
    .filter(word => word.length > 2);

  // Scorer chaque FAQ
  const scored = allFAQs.map(faq => {
    const keywords = faq.keywords.join(' ').toLowerCase();
    const question = faq.question_fr.toLowerCase();
    const category = faq.category.toLowerCase();

    let score = 0;

    queryWords.forEach(word => {
      // Match keywords (poids 3)
      if (keywords.includes(word)) score += 3;

      // Match question (poids 2)
      if (question.includes(word)) score += 2;

      // Match category (poids 1)
      if (category.includes(word)) score += 1;
    });

    return { ...faq, score };
  });

  // Trier par score et priorit√©
  scored.sort((a, b) => {
    if (b.score !== a.score) return b.score - a.score;
    return b.offline_priority - a.offline_priority;
  });

  // Retourner top r√©sultats avec score > 0
  return scored.filter(faq => faq.score > 0).slice(0, 5);
};

/**
 * Sauvegarder conversation
 */
export const saveConversation = async (message) => {
  const db = await initDB();
  
  const conversation = {
    ...message,
    timestamp: Date.now()
  };

  await db.add('conversations', conversation);
};

/**
 * R√©cup√©rer historique conversations
 */
export const getConversationHistory = async (limit = 50) => {
  const db = await initDB();
  const tx = db.transaction('conversations', 'readonly');
  const index = tx.store.index('timestamp');
  
  const conversations = await index.getAll();
  
  return conversations
    .sort((a, b) => b.timestamp - a.timestamp)
    .slice(0, limit);
};

/**
 * Effacer historique
 */
export const clearHistory = async () => {
  const db = await initDB();
  await db.clear('conversations');
};

/**
 * Obtenir statistiques
 */
export const getStats = async () => {
  const db = await initDB();

  const [faqCount, embCount, convCount] = await Promise.all([
    db.count('faqs'),
    db.count('embeddings'),
    db.count('conversations')
  ]);

  return {
    faqs: faqCount,
    embeddings: embCount,
    conversations: convCount
  };
};
FICHIER: frontend/src/services/api/APIService.js
javascript
/**
 * Service API pour mode online
 */

class APIService {
  constructor() {
    this.baseURL = process.env.REACT_APP_API_URL || 'http://localhost:5000/api';
    this.timeout = 5000; // 5s timeout
  }

  /**
   * Requ√™te chat
   */
  async chat(data) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);

    try {
      const response = await fetch(`${this.baseURL}/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(data),
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      return await response.json();

    } catch (error) {
      clearTimeout(timeoutId);
      
      if (error.name === 'AbortError') {
        throw new Error('Timeout: connexion trop lente');
      }
      
      throw error;
    }
  }

  /**
   * Health check
   */
  async healthCheck() {
    try {
      const response = await fetch(`${this.baseURL}/health`, {
        method: 'GET',
        signal: AbortSignal.timeout(2000)
      });

      return response.ok;
    } catch {
      return false;
    }
  }
}

export default new APIService();
FICHIER: frontend/src/hooks/useChat.js
javascript
/**
 * Hook personnalis√© pour gestion chat
 */

import { useState, useCallback } from 'react';
import AIService from '../services/aiEngine/AIService';
import { saveConversation } from '../services/storage/IndexedDBManager';

export const useChat = (language = 'fr') => {
  const [messages, setMessages] = useState([]);
  const [isLoading, setIsLoading] = useState(false);
  const [currentMode, setCurrentMode] = useState(null);

  /**
   * Envoyer message
   */
  const sendMessage = useCallback(async (query) => {
    if (!query.trim() || isLoading) return;

    // Message utilisateur
    const userMessage = {
      id: Date.now(),
      role: 'user',
      content: query,
      timestamp: new Date().toISOString()
    };

    setMessages(prev => [...prev, userMessage]);
    setIsLoading(true);

    try {
      // Obtenir r√©ponse IA
      const response = await AIService.getResponse(query, language);

      // Message assistant
      const assistantMessage = {
        id: Date.now() + 1,
        role: 'assistant',
        content: response.answer,
        mode: response.mode,
        confidence: response.confidence,
        sources: response.sources || [],
        responseTime: response.responseTime,
        timestamp: new Date().toISOString()
      };

      setMessages(prev => [...prev, assistantMessage]);
      setCurrentMode(response.mode);

      // Sauvegarder conversation
      await saveConversation({
        query,
        response: response.answer,
        mode: response.mode
      });

    } catch (error) {
      console.error('Erreur envoi message:', error);

      // Message erreur
      const errorMessage = {
        id: Date.now() + 1,
        role: 'assistant',
        content: language === 'fr'
          ? "D√©sol√©, une erreur s'est produite. Veuillez r√©essayer."
          : "ÿπÿ∞ÿ±ÿßÿå ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ.",
        error: true,
        timestamp: new Date().toISOString()
      };

      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  }, [isLoading, language]);

  /**
   * Effacer messages
   */
  const clearMessages = useCallback(() => {
    setMessages([]);
  }, []);

  /**
   * R√©essayer dernier message
   */
  const retryLastMessage = useCallback(() => {
    const lastUserMessage = [...messages]
      .reverse()
      .find(msg => msg.role === 'user');

    if (lastUserMessage) {
      sendMessage(lastUserMessage.content);
    }
  }, [messages, sendMessage]);

  return {
    messages,
    isLoading,
    currentMode,
    sendMessage,
    clearMessages,
    retryLastMessage
  };
};
FICHIER: frontend/src/hooks/useConnection.js
javascript
/**
 * Hook pour surveiller √©tat connexion
 */

import { useState, useEffect } from 'react';
import AIService from '../services/aiEngine/AIService';

export const useConnection = () => {
  const [status, setStatus] = useState('online');
  const [isOnline, setIsOnline] = useState(navigator.onLine);

  useEffect(() => {
    const updateStatus = () => {
      const online = navigator.onLine;
      setIsOnline(online);
      
      if (online) {
        const quality = AIService.getConnectionQuality();
        setStatus(quality);
      } else {
        setStatus('offline');
      }
    };

    // Initial check
    updateStatus();

    // Listeners
    window.addEventListener('online', updateStatus);
    window.addEventListener('offline', updateStatus);

    // V√©rifier p√©riodiquement
    const interval = setInterval(updateStatus, 5000);

    return () => {
      window.removeEventListener('online', updateStatus);
      window.removeEventListener('offline', updateStatus);
      clearInterval(interval);
    };
  }, []);

  const getStatusColor = () => {
    switch (status) {
      case 'offline': return '#f44336';
      case 'low': return '#ff9800';
      case 'medium': return '#ffc107';
      case 'high':
      case 'online': return '#4caf50';
      default: return '#9e9e9e';
    }
  };

  const getStatusIcon = () => {
    switch (status) {
      case 'offline': return 'üî¥';
      case 'low': return 'üü°';
      case 'medium': return 'üü°';
      case 'high':
      case 'online': return 'üü¢';
      default: return '‚ö™';
    }
  };

  return {
    status,
    isOnline,
    getStatusColor,
    getStatusIcon
  };
};
FICHIER: frontend/src/components/Chat/ChatInterface.jsx
jsx
/**
 * Interface principale du chat
 */

import React, { useEffect, useRef } from 'react';
import { useTranslation } from 'react-i18next';
import { useChat } from '../../hooks/useChat';
import { useConnection } from '../../hooks/useConnection';
import ChatHeader from './ChatHeader';
import MessageList from './MessageList';
import InputBox from './InputBox';
import './ChatInterface.css';

const ChatInterface = () => {
  const { t, i18n } = useTranslation();
  const { status, getStatusIcon } = useConnection();
  const { messages, isLoading, currentMode, sendMessage, clearMessages } = useChat(i18n.language);
  
  const messagesEndRef = useRef(null);

  // Auto-scroll vers bas
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  return (
    <div className="chat-interface" dir={i18n.dir()}>
      <ChatHeader
        status={status}
        statusIcon={getStatusIcon()}
        currentMode={currentMode}
        onClearChat={clearMessages}
      />

      <MessageList
        messages={messages}
        isLoading={isLoading}
        language={i18n.language}
      />

      <div ref={messagesEndRef} />

      <InputBox
        onSend={sendMessage}
        disabled={isLoading}
        placeholder={t('ask_question')}
      />
    </div>
  );
};

export default ChatInterface;
FICHIER: frontend/src/components/Chat/ChatHeader.jsx
jsx
/**
 * En-t√™te du chat avec status et langues
 */

import React from 'react';
import { useTranslation } from 'react-i18next';
import './ChatHeader.css';

const ChatHeader = ({ status, statusIcon, currentMode, onClearChat }) => {
  const { t, i18n } = useTranslation();

  const changeLanguage = (lang) => {
    i18n.changeLanguage(lang);
    document.body.dir = i18n.dir(lang);
  };

  return (
    <header className="chat-header">
      <div className="header-left">
        <h1 className="header-title">{t('welcome')}</h1>
        <div className="header-subtitle">FST Nouakchott - Nuit de l'Info 2025</div>
      </div>

      <div className="header-center">
        <div className={`status-badge status-${status}`}>
          <span className="status-icon">{statusIcon}</span>
          <span className="status-text">{t(`${status}_mode`)}</span>
        </div>
        {currentMode && (
          <div className="mode-badge">
            Mode: {currentMode}
          </div>
        )}
      </div>

      <div className="header-right">
        <div className="language-switcher">
          <button
            className={`lang-btn ${i18n.language === 'fr' ? 'active' : ''}`}
            onClick={() => changeLanguage('fr')}
          >
            FR
          </button>
          <button
            className={`lang-btn ${i18n.language === 'ar' ? 'active' : ''}`}
            onClick={() => changeLanguage('ar')}
          >
            ÿßŸÑÿπÿ±ÿ®Ÿäÿ©
          </button>
        </div>

        <button
          className="clear-btn"
          onClick={onClearChat}
          title={t('clear_chat')}
        >
          üóëÔ∏è
        </button>
      </div>
    </header>
  );
};

export default ChatHeader;
FICHIER: frontend/src/components/Chat/MessageList.jsx
jsx
/**
 * Liste des messages
 */

import React from 'react';
import MessageBubble from './MessageBubble';
import LoadingIndicator from '../UI/LoadingIndicator';
import './MessageList.css';

const MessageList = ({ messages, isLoading, language }) => {
  return (
    <div className="message-list">
      {messages.length === 0 && (
        <div className="welcome-message">
          <div className="welcome-icon">ü§ñ</div>
          <h2>
            {language === 'fr' 
              ? 'Bienvenue sur l\'Assistant IA' 
              : 'ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ŸÉ ŸÅŸä ŸÖÿ≥ÿßÿπÿØ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä'}
          </h2>
          <p>
            {language === 'fr'
              ? 'Posez vos questions sur la Nuit de l\'Info'
              : 'ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ™ŸÉ ÿ≠ŸàŸÑ ŸÑŸäŸÑÿ© ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™Ÿäÿ©'}
          </p>
          
          <div className="example-questions">
            <p className="example-title">
              {language === 'fr' ? 'Exemples de questions:' : 'ÿ£ŸÖÿ´ŸÑÿ© ÿπŸÑŸâ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ©:'}
            </p>
            <div className="example-list">
              <span className="example-tag">
                {language === 'fr' ? 'Comment participer?' : 'ŸÉŸäŸÅ ÿ£ÿ¥ÿßÿ±ŸÉÿü'}
              </span>
              <span className="example-tag">
                {language === 'fr' ? 'R√®glement' : 'ÿßŸÑŸÑŸàÿßÿ¶ÿ≠'}
              </span>
              <span className="example-tag">
                {language === 'fr' ? 'Horaires' : 'ÿßŸÑŸÖŸàÿßÿπŸäÿØ'}
              </span>
            </div>
          </div>
        </div>
      )}

      {messages.map((message) => (
        <MessageBubble
          key={message.id}
          message={message}
          language={language}
        />
      ))}

      {isLoading && <LoadingIndicator language={language} />}
    </div>
  );
};

export default MessageList;
FICHIER: frontend/src/components/Chat/MessageBubble.jsx
jsx
/**
 * Bulle de message individuelle
 */

import React, { useState } from 'react';
import './MessageBubble.css';

const MessageBubble = ({ message, language }) => {
  const [showSources, setShowSources] = useState(false);

  const isUser = message.role === 'user';

  return (
    <div className={`message-bubble ${isUser ? 'user' : 'assistant'}`}>
      <div className="message-content">
        <div className="message-text">
          {message.content}
        </div>

        {!isUser && message.mode && (
          <div className="message-metadata">
            <span className={`mode-tag mode-${message.mode}`}>
              {message.mode}
            </span>
            
            {message.confidence !== undefined && (
              <span className="confidence-tag">
                {Math.round(message.confidence * 100)}%
              </span>
            )}
            
            {message.responseTime && (
              <span className="time-tag">
                {message.responseTime}ms
              </span>
            )}
          </div>
        )}

        {!isUser && message.sources && message.sources.length > 0 && (
          <div className="message-sources">
            <button
              className="sources-toggle"
              onClick={() => setShowSources(!showSources)}
            >
              üìö {language === 'fr' ? 'Sources' : 'ÿßŸÑŸÖÿµÿßÿØÿ±'} ({message.sources.length})
            </button>

            {showSources && (
              <div className="sources-list">
                {message.sources.map((source, idx) => (
                  <div key={idx} className="source-item">
                    <div className="source-question">
                      {source[`question_${language}`] || source.question_fr}
                    </div>
                    {source.similarity && (
                      <div className="source-similarity">
                        {Math.round(source.similarity * 100)}%
                      </div>
                    )}
                  </div>
                ))}
              </div>
            )}
          </div>
        )}
      </div>

      <div className="message-time">
        {new Date(message.timestamp).toLocaleTimeString()}
      </div>
    </div>
  );
};

export default MessageBubble;
FICHIER: frontend/src/components/Chat/InputBox.jsx
jsx
/**
 * Zone de saisie
 */

import React, { useState, useRef } from 'react';
import './InputBox.css';

const InputBox = ({ onSend, disabled, placeholder }) => {
  const [input, setInput] = useState('');
  const inputRef = useRef(null);

  const handleSubmit = (e) => {
    e.preventDefault();
    
    if (input.trim() && !disabled) {
      onSend(input.trim());
      setInput('');
      inputRef.current?.focus();
    }
  };

  const handleKeyDown = (e) => {
    // Ctrl+Enter pour envoyer
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSubmit(e);
    }
  };

  return (
    <form className="input-box" onSubmit={handleSubmit}>
      <textarea
        ref={inputRef}
        className="input-field"
        value={input}
        onChange={(e) => setInput(e.target.value)}
        onKeyDown={handleKeyDown}
        placeholder={placeholder}
        disabled={disabled}
        rows={1}
        maxLength={500}
      />

      <button
        type="submit"
        className="send-button"
        disabled={disabled || !input.trim()}
      >
        {disabled ? '‚è≥' : '‚û§'}
      </button>
    </form>
  );
};

export default InputBox;
FICHIER: frontend/src/components/UI/LoadingIndicator.jsx
jsx
/**
 * Indicateur de chargement
 */

import React from 'react';
import './LoadingIndicator.css';

const LoadingIndicator = ({ language }) => {
  return (
    <div className="loading-indicator">
      <div className="loading-dots">
        <span className="dot"></span>
        <span className="dot"></span>
        <span className="dot"></span>
      </div>
      <div className="loading-text">
        {language === 'fr' ? 'R√©flexion en cours' : 'ÿ¨ÿßÿ±Ÿä ÿßŸÑÿ™ŸÅŸÉŸäÿ±'}...
      </div>
    </div>
  );
};

export default LoadingIndicator;
FICHIER: frontend/src/styles/ChatInterface.css
css
.chat-interface {
  display: flex;
  flex-direction: column;
  height: 100vh;
  max-width: 1200px;
  margin: 0 auto;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}

/* Responsive */
@media (max-width: 768px) {
  .chat-interface {
    max-width: 100%;
  }
}
FICHIER: frontend/src/styles/ChatHeader.css
css
.chat-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 1rem 1.5rem;
  background: rgba(255, 255, 255, 0.95);
  backdrop-filter: blur(10px);
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
  z-index: 10;
}

.header-left {
  flex: 1;
}

.header-title {
  font-size: 1.3rem;
  font-weight: 700;
  margin: 0;
  color: #1a202c;
}

.header-subtitle {
  font-size: 0.85rem;
  color: #718096;
  margin-top: 0.2rem;
}

.header-center {
  display: flex;
  gap: 0.75rem;
  align-items: center;
}

.status-badge {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.5rem 1rem;
  border-radius: 20px;
  font-size: 0.9rem;
  font-weight: 600;
  transition: all 0.3s ease;
}

.status-badge.status-offline {
  background: #fee;
  color: #c53030;
}

.status-badge.status-low,
.status-badge.status-medium {
  background: #fffaf0;
  color: #c05621;
}

.status-badge.status-high,
.status-badge.status-online {
  background: #f0fff4;
  color: #22543d;
}

.mode-badge {
  padding: 0.4rem 0.8rem;
  background: #edf2f7;
  border-radius: 12px;
  font-size: 0.8rem;
  color: #4a5568;
}

.header-right {
  display: flex;
  gap: 1rem;
  align-items: center;
}

.language-switcher {
  display: flex;
  gap: 0.5rem;
  background: #edf2f7;
  padding: 0.25rem;
  border-radius: 12px;
}

.lang-btn {
  padding: 0.5rem 1rem;
  border: none;
  background: transparent;
  border-radius: 8px;
  cursor: pointer;
  font-weight: 600;
  transition: all 0.2s;
  color: #4a5568;
}

.lang-btn.active {
  background: white;
  color: #667eea;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

.clear-btn {
  padding: 0.5rem;
  border: none;
  background: #edf2f7;
  border-radius: 8px;
  cursor: pointer;
  font-size: 1.2rem;
  transition: all 0.2s;
}

.clear-btn:hover {
  background: #e2e8f0;
  transform: scale(1.05);
}

/* RTL Support */
[dir="rtl"] .chat-header {
  direction: rtl;
}

[dir="rtl"] .header-left {
  text-align: right;
}

/* Mobile */
@media (max-width: 768px) {
  .chat-header {
    flex-wrap: wrap;
    padding: 1rem;
  }

  .header-center {
    order: 3;
    width: 100%;
    justify-content: center;
    margin-top: 0.75rem;
  }

  .header-title {
    font-size: 1.1rem;
  }

  .header-subtitle {
    font-size: 0.75rem;
  }
}
FICHIER: frontend/src/styles/MessageList.css
css
.message-list {
  flex: 1;
  overflow-y: auto;
  padding: 1.5rem;
  background: rgba(255, 255, 255, 0.9);
  backdrop-filter: blur(10px);
}

.welcome-message {
  text-align: center;
  padding: 3rem 1rem;
  max-width: 600px;
  margin: 0 auto;
}

.welcome-icon {
  font-size: 4rem;
  margin-bottom: 1rem;
  animation: bounce 2s infinite;
}

@keyframes bounce {
  0%, 100% { transform: translateY(0); }
  50% { transform: translateY(-10px); }
}

.welcome-message h2 {
  color: #1a202c;
  margin-bottom: 0.5rem;
}

.welcome-message p {
  color: #718096;
  font-size: 1.1rem;
  margin-bottom: 2rem;
}

.example-questions {
  margin-top: 2rem;
}

.example-title {
  font-weight: 600;
  color: #4a5568;
  margin-bottom: 1rem;
}

.example-list {
  display: flex;
  flex-wrap: wrap;
  gap: 0.75rem;
  justify-content: center;
}

.example-tag {
  padding: 0.5rem 1rem;
  background: white;
  border: 2px solid #e2e8f0;
  border-radius: 20px;
  cursor: pointer;
  transition: all 0.2s;
  font-size: 0.9rem;
}

.example-tag:hover {
  border-color: #667eea;
  background: #f7fafc;
  transform: translateY(-2px);
}

/* Scrollbar styling */
.message-list::-webkit-scrollbar {
  width: 8px;
}

.message-list::-webkit-scrollbar-track {
  background: rgba(0, 0, 0, 0.05);
}

.message-list::-webkit-scrollbar-thumb {
  background: rgba(0, 0, 0, 0.2);
  border-radius: 4px;
}

.message-list::-webkit-scrollbar-thumb:hover {
  background: rgba(0, 0, 0, 0.3);
}
FRONTEND REACT - PARTIE 4 (STYLES & CONFIG)
FICHIER: frontend/src/styles/MessageBubble.css
css
.message-bubble {
  display: flex;
  margin-bottom: 1.5rem;
  animation: slideIn 0.3s ease-out;
}

@keyframes slideIn {
  from {
    opacity: 0;
    transform: translateY(10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.message-bubble.user {
  justify-content: flex-end;
}

.message-bubble.assistant {
  justify-content: flex-start;
}

.message-content {
  max-width: 70%;
  position: relative;
}

.message-bubble.user .message-content {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  border-radius: 18px 18px 4px 18px;
  padding: 1rem 1.25rem;
  box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
}

.message-bubble.assistant .message-content {
  background: white;
  color: #1a202c;
  border-radius: 18px 18px 18px 4px;
  padding: 1rem 1.25rem;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
  border: 1px solid #e2e8f0;
}

.message-text {
  font-size: 0.95rem;
  line-height: 1.6;
  word-wrap: break-word;
  white-space: pre-wrap;
}

.message-metadata {
  display: flex;
  gap: 0.5rem;
  margin-top: 0.75rem;
  flex-wrap: wrap;
}

.mode-tag,
.confidence-tag,
.time-tag {
  padding: 0.25rem 0.6rem;
  border-radius: 8px;
  font-size: 0.75rem;
  font-weight: 600;
  backdrop-filter: blur(10px);
}

.mode-tag.mode-offline {
  background: rgba(244, 67, 54, 0.15);
  color: #c53030;
}

.mode-tag.mode-hybrid {
  background: rgba(255, 193, 7, 0.15);
  color: #c05621;
}

.mode-tag.mode-online {
  background: rgba(76, 175, 80, 0.15);
  color: #22543d;
}

.confidence-tag {
  background: rgba(33, 150, 243, 0.15);
  color: #2c5282;
}

.time-tag {
  background: rgba(156, 39, 176, 0.15);
  color: #6b46c1;
}

.message-sources {
  margin-top: 1rem;
  padding-top: 1rem;
  border-top: 1px solid #e2e8f0;
}

.sources-toggle {
  background: #f7fafc;
  border: 1px solid #e2e8f0;
  border-radius: 8px;
  padding: 0.5rem 0.75rem;
  cursor: pointer;
  font-size: 0.85rem;
  color: #4a5568;
  transition: all 0.2s;
  width: 100%;
  text-align: left;
}

.sources-toggle:hover {
  background: #edf2f7;
  border-color: #cbd5e0;
}

.sources-list {
  margin-top: 0.75rem;
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.source-item {
  background: #f7fafc;
  border-radius: 8px;
  padding: 0.75rem;
  display: flex;
  justify-content: space-between;
  align-items: center;
  gap: 0.75rem;
}

.source-question {
  flex: 1;
  font-size: 0.85rem;
  color: #2d3748;
}

.source-similarity {
  background: #667eea;
  color: white;
  padding: 0.25rem 0.5rem;
  border-radius: 6px;
  font-size: 0.75rem;
  font-weight: 600;
  white-space: nowrap;
}

.message-time {
  font-size: 0.7rem;
  color: #a0aec0;
  margin-top: 0.5rem;
  text-align: right;
}

.message-bubble.user .message-time {
  text-align: left;
}

/* RTL Support */
[dir="rtl"] .message-bubble.user {
  justify-content: flex-start;
}

[dir="rtl"] .message-bubble.assistant {
  justify-content: flex-end;
}

[dir="rtl"] .message-bubble.user .message-content {
  border-radius: 18px 18px 18px 4px;
}

[dir="rtl"] .message-bubble.assistant .message-content {
  border-radius: 18px 18px 4px 18px;
}

/* Mobile */
@media (max-width: 768px) {
  .message-content {
    max-width: 85%;
  }

  .message-text {
    font-size: 0.9rem;
  }
}
FICHIER: frontend/src/styles/InputBox.css
css
.input-box {
  display: flex;
  gap: 0.75rem;
  padding: 1rem 1.5rem;
  background: white;
  border-top: 1px solid #e2e8f0;
  align-items: flex-end;
}

.input-field {
  flex: 1;
  padding: 0.85rem 1rem;
  border: 2px solid #e2e8f0;
  border-radius: 20px;
  font-size: 0.95rem;
  font-family: inherit;
  resize: none;
  outline: none;
  transition: all 0.2s;
  max-height: 120px;
  min-height: 48px;
}

.input-field:focus {
  border-color: #667eea;
  box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
}

.input-field:disabled {
  background: #f7fafc;
  cursor: not-allowed;
  color: #a0aec0;
}

.input-field::placeholder {
  color: #a0aec0;
}

.send-button {
  width: 48px;
  height: 48px;
  border: none;
  border-radius: 50%;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  font-size: 1.2rem;
  cursor: pointer;
  transition: all 0.2s;
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
}

.send-button:hover:not(:disabled) {
  transform: scale(1.05);
  box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
}

.send-button:active:not(:disabled) {
  transform: scale(0.95);
}

.send-button:disabled {
  background: #cbd5e0;
  cursor: not-allowed;
  opacity: 0.6;
}

/* Auto-resize textarea */
.input-field {
  overflow-y: hidden;
}

/* RTL Support */
[dir="rtl"] .input-box {
  direction: rtl;
}

/* Mobile */
@media (max-width: 768px) {
  .input-box {
    padding: 0.75rem 1rem;
    gap: 0.5rem;
  }

  .input-field {
    font-size: 0.9rem;
    padding: 0.75rem;
  }

  .send-button {
    width: 44px;
    height: 44px;
  }
}
FICHIER: frontend/src/styles/LoadingIndicator.css
css
.loading-indicator {
  display: flex;
  align-items: center;
  gap: 1rem;
  padding: 1.5rem;
  background: white;
  border-radius: 18px;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
  max-width: 200px;
  margin-bottom: 1.5rem;
  animation: slideIn 0.3s ease-out;
}

.loading-dots {
  display: flex;
  gap: 0.4rem;
}

.dot {
  width: 10px;
  height: 10px;
  border-radius: 50%;
  background: #667eea;
  animation: bounce 1.4s infinite ease-in-out both;
}

.dot:nth-child(1) {
  animation-delay: -0.32s;
}

.dot:nth-child(2) {
  animation-delay: -0.16s;
}

@keyframes bounce {
  0%, 80%, 100% {
    transform: scale(0);
  }
  40% {
    transform: scale(1);
  }
}

.loading-text {
  font-size: 0.85rem;
  color: #4a5568;
  font-weight: 500;
}

/* RTL Support */
[dir="rtl"] .loading-indicator {
  margin-right: 0;
  margin-left: auto;
}
FICHIER: frontend/src/styles/global.css
css
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen',
    'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue',
    sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  overflow: hidden;
}

code {
  font-family: source-code-pro, Menlo, Monaco, Consolas, 'Courier New',
    monospace;
}

/* Scrollbar global styling */
::-webkit-scrollbar {
  width: 8px;
  height: 8px;
}

::-webkit-scrollbar-track {
  background: rgba(0, 0, 0, 0.05);
}

::-webkit-scrollbar-thumb {
  background: rgba(0, 0, 0, 0.2);
  border-radius: 4px;
}

::-webkit-scrollbar-thumb:hover {
  background: rgba(0, 0, 0, 0.3);
}

/* RTL Support */
[dir="rtl"] {
  direction: rtl;
  text-align: right;
}

/* Utility classes */
.visually-hidden {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  white-space: nowrap;
  border-width: 0;
}
FICHIER: frontend/src/locales/fr.json
json
{
  "welcome": "Assistant IA - Nuit de l'Info 2025",
  "ask_question": "Posez votre question...",
  "send": "Envoyer",
  "clear_chat": "Effacer la conversation",
  "offline_mode": "Mode hors ligne",
  "low_mode": "Connexion faible",
  "medium_mode": "Connexion moyenne",
  "high_mode": "Connexion rapide",
  "online_mode": "En ligne",
  "thinking": "R√©flexion en cours",
  "sources": "Sources",
  "confidence": "Confiance",
  "response_time": "Temps de r√©ponse",
  "no_results": "Aucun r√©sultat trouv√©",
  "error_message": "Une erreur s'est produite. Veuillez r√©essayer.",
  "welcome_title": "Bienvenue sur l'Assistant IA",
  "welcome_subtitle": "Posez vos questions sur la Nuit de l'Info",
  "example_questions": "Exemples de questions:",
  "retry": "R√©essayer",
  "mode": "Mode"
}
FICHIER: frontend/src/locales/ar.json
json
{
  "welcome": "ŸÖÿ≥ÿßÿπÿØ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä - ŸÑŸäŸÑÿ© ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™Ÿäÿ© 2025",
  "ask_question": "ÿßÿ∑ÿ±ÿ≠ ÿ≥ÿ§ÿßŸÑŸÉ...",
  "send": "ÿ•ÿ±ÿ≥ÿßŸÑ",
  "clear_chat": "ŸÖÿ≥ÿ≠ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©",
  "offline_mode": "Ÿàÿ∂ÿπ ÿπÿØŸÖ ÿßŸÑÿßÿ™ÿµÿßŸÑ",
  "low_mode": "ÿßÿ™ÿµÿßŸÑ ÿ∂ÿπŸäŸÅ",
  "medium_mode": "ÿßÿ™ÿµÿßŸÑ ŸÖÿ™Ÿàÿ≥ÿ∑",
  "high_mode": "ÿßÿ™ÿµÿßŸÑ ÿ≥ÿ±Ÿäÿπ",
  "online_mode": "ŸÖÿ™ÿµŸÑ",
  "thinking": "ÿ¨ÿßÿ±Ÿä ÿßŸÑÿ™ŸÅŸÉŸäÿ±",
  "sources": "ÿßŸÑŸÖÿµÿßÿØÿ±",
  "confidence": "ÿßŸÑÿ´ŸÇÿ©",
  "response_time": "ŸàŸÇÿ™ ÿßŸÑÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ©",
  "no_results": "ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ŸÜÿ™ÿßÿ¶ÿ¨",
  "error_message": "ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ.",
  "welcome_title": "ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ŸÉ ŸÅŸä ŸÖÿ≥ÿßÿπÿØ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä",
  "welcome_subtitle": "ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ™ŸÉ ÿ≠ŸàŸÑ ŸÑŸäŸÑÿ© ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™Ÿäÿ©",
  "example_questions": "ÿ£ŸÖÿ´ŸÑÿ© ÿπŸÑŸâ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ©:",
  "retry": "ÿ•ÿπÿßÿØÿ© ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ©",
  "mode": "ÿßŸÑŸàÿ∂ÿπ"
}
FICHIER: frontend/src/i18n.js
javascript
import i18n from 'i18next';
import { initReactI18next } from 'react-i18next';

import translationFR from './locales/fr.json';
import translationAR from './locales/ar.json';

const resources = {
  fr: {
    translation: translationFR
  },
  ar: {
    translation: translationAR
  }
};

i18n
  .use(initReactI18next)
  .init({
    resources,
    lng: 'fr', // Langue par d√©faut
    fallbackLng: 'fr',
    interpolation: {
      escapeValue: false // React √©chappe d√©j√†
    },
    react: {
      useSuspense: false
    }
  });

export default i18n;
FICHIER: frontend/src/App.jsx
jsx
import React, { useEffect, useState } from 'react';
import ChatInterface from './components/Chat/ChatInterface';
import { loadInitialData } from './services/storage/IndexedDBManager';
import './i18n';
import './styles/global.css';

function App() {
  const [isReady, setIsReady] = useState(false);
  const [error, setError] = useState(null);

  useEffect(() => {
    // Initialiser l'application
    const initApp = async () => {
      try {
        console.log('üöÄ Initialisation de l\'application...');
        
        // Charger donn√©es dans IndexedDB
        const success = await loadInitialData();
        
        if (success) {
          console.log('‚úÖ Application pr√™te');
          setIsReady(true);
        } else {
          throw new Error('√âchec du chargement des donn√©es');
        }
      } catch (err) {
        console.error('‚ùå Erreur initialisation:', err);
        setError(err.message);
        // Continuer quand m√™me
        setIsReady(true);
      }
    };

    initApp();
  }, []);

  if (error) {
    return (
      <div style={{
        display: 'flex',
        flexDirection: 'column',
        alignItems: 'center',
        justifyContent: 'center',
        height: '100vh',
        padding: '2rem',
        textAlign: 'center'
      }}>
        <h1>‚ö†Ô∏è Avertissement</h1>
        <p>Certaines fonctionnalit√©s peuvent √™tre limit√©es.</p>
        <p style={{ fontSize: '0.9rem', color: '#666', marginTop: '1rem' }}>
          {error}
        </p>
        <button
          onClick={() => window.location.reload()}
          style={{
            marginTop: '1rem',
            padding: '0.75rem 1.5rem',
            background: '#667eea',
            color: 'white',
            border: 'none',
            borderRadius: '8px',
            cursor: 'pointer'
          }}
        >
          R√©essayer
        </button>
      </div>
    );
  }

  if (!isReady) {
    return (
      <div style={{
        display: 'flex',
        flexDirection: 'column',
        alignItems: 'center',
        justifyContent: 'center',
        height: '100vh',
        gap: '1rem'
      }}>
        <div style={{
          width: '50px',
          height: '50px',
          border: '4px solid #f3f3f3',
          borderTop: '4px solid #667eea',
          borderRadius: '50%',
          animation: 'spin 1s linear infinite'
        }}></div>
        <p>Chargement de l'assistant IA...</p>
        <style>{`
          @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
          }
        `}</style>
      </div>
    );
  }

  return <ChatInterface />;
}

export default App;
FICHIER: frontend/src/index.jsx
jsx
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';
import './styles/global.css';

// Enregistrer Service Worker
if ('serviceWorker' in navigator) {
  window.addEventListener('load', () => {
    navigator.serviceWorker
      .register('/service-worker.js')
      .then(registration => {
        console.log('‚úÖ Service Worker enregistr√©:', registration.scope);
      })
      .catch(error => {
        console.error('‚ùå Erreur Service Worker:', error);
      });
  });
}

const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
);
FICHIER: frontend/public/service-worker.js
javascript
const CACHE_NAME = 'assistant-ia-v1.0.0';
const OFFLINE_CACHE = 'offline-v1';

// Assets √† pr√©-cacher
const PRECACHE_URLS = [
  '/',
  '/index.html',
  '/manifest.json',
  '/data/faqs.json',
  '/data/embeddings.json'
];

// Installation
self.addEventListener('install', (event) => {
  console.log('üì¶ Service Worker: Installation...');
  
  event.waitUntil(
    caches.open(OFFLINE_CACHE)
      .then((cache) => {
        console.log('üì¶ Pr√©-cache des assets');
        return cache.addAll(PRECACHE_URLS);
      })
      .catch((err) => {
        console.error('Erreur pr√©-cache:', err);
      })
  );
  
  self.skipWaiting();
});

// Activation
self.addEventListener('activate', (event) => {
  console.log('‚úÖ Service Worker: Activation');
  
  event.waitUntil(
    caches.keys().then((cacheNames) => {
      return Promise.all(
        cacheNames.map((cacheName) => {
          if (cacheName !== CACHE_NAME && cacheName !== OFFLINE_CACHE) {
            console.log('üóëÔ∏è Suppression ancien cache:', cacheName);
            return caches.delete(cacheName);
          }
        })
      );
    })
  );
  
  self.clients.claim();
});

// Fetch avec strat√©gies
self.addEventListener('fetch', (event) => {
  const { request } = event;
  const url = new URL(request.url);

  // Ignorer requ√™tes non-GET
  if (request.method !== 'GET') {
    return;
  }

  // Ignorer chrome-extension et autres
  if (!url.protocol.startsWith('http')) {
    return;
  }

  // Strat√©gie selon type de ressource
  if (request.destination === 'script' || 
      request.destination === 'style' ||
      request.destination === 'image') {
    // Cache-first pour assets statiques
    event.respondWith(cacheFirst(request));
  } else if (url.pathname.includes('/data/')) {
    // Cache-first pour donn√©es JSON
    event.respondWith(cacheFirst(request));
  } else if (url.pathname.includes('/api/')) {
    // Network-first pour API avec timeout
    event.respondWith(networkFirstWithTimeout(request, 3000));
  } else {
    // Stale-while-revalidate pour pages HTML
    event.respondWith(staleWhileRevalidate(request));
  }
});

// Cache-first strategy
async function cacheFirst(request) {
  const cached = await caches.match(request);
  if (cached) {
    return cached;
  }

  try {
    const response = await fetch(request);
    
    if (response.ok) {
      const cache = await caches.open(CACHE_NAME);
      cache.put(request, response.clone());
    }
    
    return response;
  } catch (error) {
    console.error('Fetch failed:', error);
    return new Response('Offline', { status: 503 });
  }
}

// Network-first avec timeout
async function networkFirstWithTimeout(request, timeout) {
  try {
    const response = await Promise.race([
      fetch(request),
      new Promise((_, reject) =>
        setTimeout(() => reject(new Error('timeout')), timeout)
      )
    ]);

    // Cacher si succ√®s
    if (response.ok) {
      const cache = await caches.open(CACHE_NAME);
      cache.put(request, response.clone());
    }

    return response;
  } catch (error) {
    // Fallback vers cache
    const cached = await caches.match(request);
    if (cached) {
      return cached;
    }

    // R√©ponse offline par d√©faut
    return new Response(
      JSON.stringify({
        error: 'offline',
        message: 'Mode hors ligne activ√©'
      }),
      {
        status: 503,
        headers: { 'Content-Type': 'application/json' }
      }
    );
  }
}

// Stale-while-revalidate
async function staleWhileRevalidate(request) {
  const cached = await caches.match(request);

  const fetchPromise = fetch(request).then((response) => {
    if (response.ok) {
      const cache = caches.open(CACHE_NAME);
      cache.then((c) => c.put(request, response.clone()));
    }
    return response;
  });

  return cached || fetchPromise;
}

// Messages du client
self.addEventListener('message', (event) => {
  if (event.data && event.data.type === 'SKIP_WAITING') {
    self.skipWaiting();
  }
});
FICHIER: frontend/.env.example
text
# API Backend (optionnel)
REACT_APP_API_URL=http://localhost:5000/api

# Analytics (optionnel)
REACT_APP_ANALYTICS_ID=

# Debug mode
REACT_APP_DEBUG=false
FICHIER: frontend/README.md
text
# ü§ñ Assistant IA Low-Cost - Frontend

Interface React pour l'assistant IA de la Nuit de l'Info 2025.

## üöÄ Installation Rapide

Installer d√©pendances
npm install

Lancer en d√©veloppement
npm start

Build production
npm run build

text

## üìÅ Structure

src/
‚îú‚îÄ‚îÄ components/ # Composants React
‚îú‚îÄ‚îÄ services/ # Services (IA, Storage, API)
‚îú‚îÄ‚îÄ hooks/ # Hooks personnalis√©s
‚îú‚îÄ‚îÄ styles/ # CSS
‚îî‚îÄ‚îÄ locales/ # Traductions FR/AR

text

## üéØ Fonctionnalit√©s

- ‚úÖ 3 modes: Offline, Hybride, Online
- ‚úÖ Bilingue FR/AR avec RTL
- ‚úÖ PWA avec Service Worker
- ‚úÖ IndexedDB pour offline
- ‚úÖ RAG avec embeddings
- ‚úÖ UI responsive

## üß™ Tests

Tests unitaires
npm test

Tests en mode offline
Ouvrir DevTools > Application > Service Workers > Offline
text

## üì¶ D√©ploiement

Build
npm run build

D√©ployer sur Vercel
vercel --prod

text

## üìù Configuration

Copiez `.env.example` vers `.env` et configurez les variables.

## üêõ Debug

Mode debug: `localStorage.setItem('debug', 'true')`
FICHIER: deployment/vercel.json
json
{
  "version": 2,
  "name": "assistant-ia-lowcost",
  "builds": [
    {
      "src": "frontend/package.json",
      "use": "@vercel/static-build",
      "config": {
        "distDir": "build"
      }
    }
  ],
  "routes": [
    {
      "src": "/service-worker.js",
      "headers": {
        "Cache-Control": "public, max-age=0, must-revalidate",
        "Service-Worker-Allowed": "/"
      },
      "dest": "/service-worker.js"
    },
    {
      "src": "/data/(.*)",
      "headers": {
        "Cache-Control": "public, max-age=31536000, immutable"
      },
      "dest": "/data/$1"
    },
    {
      "src": "/(.*)",
      "headers": {
        "X-Content-Type-Options": "nosniff",
        "X-Frame-Options": "DENY",
        "X-XSS-Protection": "1; mode=block"
      },
      "dest": "/$1"
    }
  ],
  "rewrites": [
    {
      "source": "/(.*)",
      "destination": "/index.html"
    }
  ]
}
FICHIER: docs/INSTALLATION.md
text
# üìò Guide d'Installation Complet

## Pr√©requis

- **Node.js** 18+ ([t√©l√©charger](https://nodejs.org))
- **Python** 3.9+ ([t√©l√©charger](https://python.org))
- **Git** ([t√©l√©charger](https://git-scm.com))
- **Chrome** ou **Firefox** (pour tests PWA)

## Installation en 10 minutes

### √âtape 1: Cloner le projet

git clone https://github.com/votre-equipe/assistant-ia-lowcost.git
cd assistant-ia-lowcost

text

### √âtape 2: Collecte des donn√©es (5-10 min)

cd data-collection

Cr√©er environnement virtuel
python -m venv venv
source venv/bin/activate # Windows: venv\Scripts\activate

Installer d√©pendances
pip install -r requirements.txt

Lancer collecte compl√®te
python 01_scraper_advanced.py
python 02_pdf_extractor.py
python 03_data_cleaner.py
python 05_embeddings_creator.py

text

### √âtape 3: Setup Frontend

cd ../frontend

Installer d√©pendances
npm install

Copier configuration
cp .env.example .env

Lancer en d√©veloppement
npm start

text

L'application s'ouvre sur http://localhost:3000

### √âtape 4: Tests des 3 modes

#### Test Offline:
1. Ouvrir DevTools (F12)
2. Application > Service Workers
3. Cocher "Offline"
4. Poser une question ‚Üí Mode üî¥ activ√©

#### Test Hybride:
1. Network tab > Throttling > Slow 3G
2. Poser une question ‚Üí Mode üü° activ√©

#### Test Online:
1. Network > No throttling
2. Poser une question ‚Üí Mode üü¢ activ√©

## Build Production

cd frontend
npm run build

Tester le build
npx serve -s build

text

## D√©ploiement Vercel

Installer CLI Vercel
npm install -g vercel

Se connecter
vercel login

D√©ployer
cd frontend
vercel --prod

text

## D√©pannage

### Probl√®me: Donn√©es pas charg√©es
**Solution**: V√©rifier `Application > IndexedDB` dans DevTools

### Probl√®me: Service Worker pas enregistr√©
**Solution**: 
- V√©rifier que vous √™tes en HTTPS (ou localhost)
- Effacer cache navigateur
- Recharger avec Ctrl+Shift+R

### Probl√®me: Erreur embeddings
**Solution**: V√©rifier que `public/data/embeddings.json` existe

## Support

üìß Email: elbenany.med-mahmoud@supnum.mr
üêõ Issues: GitHub Issues
FICHIER: README.md (Racine)
text
# ü§ñ Assistant IA Low-Cost - Nuit de l'Info 2025

**Facult√© des Sciences et Techniques - Universit√© de Nouakchott**

Assistant intelligent l√©ger pour acc√®s aux services publics avec faible connectivit√©.

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![React](https://img.shields.io/badge/React-18-blue)](https://reactjs.org/)
[![PWA](https://img.shields.io/badge/PWA-Ready-brightgreen)](https://web.dev/progressive-web-apps/)

## üéØ D√©fi

Cr√©er un assistant IA capable d'aider les utilisateurs √† acc√©der aux services publics m√™me avec une connexion Internet faible ou instable.

## ‚ú® Fonctionnalit√©s

### üö¶ 3 Modes de Fonctionnement

- **üî¥ Mode Offline**: Recherche par mots-cl√©s (< 200ms)
- **üü° Mode Hybride**: RAG + similarit√© s√©mantique (< 3s)
- **üü¢ Mode Online**: API compl√®te avec LLM (< 1s)

### üåç Multilingue

- Fran√ßais (FR)
- Arabe (AR) avec support RTL
- Interface adaptative selon langue

### üì± Progressive Web App (PWA)

- Fonctionne offline
- Installable sur mobile/desktop
- Service Worker intelligent
- IndexedDB pour stockage local

### üß† IA L√©g√®re

- Embeddings multilingues (384 dimensions)
- RAG (Retrieval-Augmented Generation)
- Mod√®le quantifi√© ONNX (optionnel)
- Pas de backend requis pour mode hybride

## üèóÔ∏è Architecture

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User Query ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Detect ‚îÇ ‚óÑ‚îÄ‚îÄ Navigator.onLine
‚îÇ Connection ‚îÇ Network Info API
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Route to Engine ‚îÇ
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
‚îÇ ‚îÇ ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê
‚îÇOffline‚îÇHybrid‚îÇOnline‚îÇ
‚îÇEngine ‚îÇEngine‚îÇEngine‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò ‚îî‚îÄ‚î¨‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
‚îÇ ‚îÇ ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇResponse‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

text

## üìä Performance

| Mode | Temps R√©ponse | Pr√©cision | Donn√©es |
|------|--------------|-----------|---------|
| Offline | < 200ms | 70% | IndexedDB |
| Hybride | < 3s | 85% | Embeddings |
| Online | < 1s | 95% | API + LLM |

## üöÄ Installation Rapide

1. Cloner
git clone https://github.com/votre-equipe/assistant-ia-lowcost.git
cd assistant-ia-lowcost

2. Collecte donn√©es (Python)
cd data-collection
pip install -r requirements.txt
python 01_scraper_advanced.py
python 03_data_cleaner.py
python 05_embeddings_creator.py

3. Frontend (React)
cd ../frontend
npm install
npm start

text

**Temps total: 10-15 minutes** ‚è±Ô∏è

üìñ [Guide d'installation d√©taill√©](docs/INSTALLATION.md)

## üì¶ Structure Projet

assistant-ia-lowcost/
‚îú‚îÄ‚îÄ data-collection/ # Scripts Python collecte donn√©es
‚îÇ ‚îú‚îÄ‚îÄ 01_scraper_advanced.py
‚îÇ ‚îú‚îÄ‚îÄ 03_data_cleaner.py
‚îÇ ‚îî‚îÄ‚îÄ 05_embeddings_creator.py
‚îÇ
‚îú‚îÄ‚îÄ frontend/ # Application React
‚îÇ ‚îú‚îÄ‚îÄ src/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ components/ # UI Components
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ services/ # IA, Storage, API
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ hooks/ # React hooks
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ styles/ # CSS
‚îÇ ‚îî‚îÄ‚îÄ public/
‚îÇ ‚îú‚îÄ‚îÄ data/ # FAQ + Embeddings
‚îÇ ‚îî‚îÄ‚îÄ service-worker.js
‚îÇ
‚îú‚îÄ‚îÄ docs/ # Documentation
‚îî‚îÄ‚îÄ deployment/ # Config d√©ploiement

text

## üß™ Tests

Tests unitaires
cd frontend
npm test

Tests modes offline/online
Voir docs/INSTALLATION.md section "Tests"
text

## üì± D√©mo

üåê **Live Demo**: [https://assistant-ia-lowcost.vercel.app](https://assistant-ia-lowcost.vercel.app)

üìπ **Vid√©o** (3min): [YouTube](https://youtube.com/...)

## üìÑ Documentation

- üìò [Installation](docs/INSTALLATION.md)
- üèóÔ∏è [Architecture](docs/ARCHITECTURE.md)
- üîå [Int√©gration](docs/API_DOCUMENTATION.md)
- üöÄ [D√©ploiement](docs/DEPLOYMENT.md)

## üë• √âquipe FST-UN

**Facult√© des Sciences et Techniques**
Universit√© de Nouakchott

- Encadrant: Pr. [Nom]
- D√©veloppeurs: [Noms √©tudiants]

## üìß Contact

üìÆ **Email**: elbenany.med-mahmoud@supnum.mr  
üåê **Site**: [https://fst.univ-nkc.mr](https://fst.univ-nkc.mr)

## üìù License

MIT License - Voir [LICENSE](LICENSE)

## üéâ Remerciements

- **Nuit de l'Info 2025**
- **Partenaires FST-UN**
- **Communaut√© Open Source**

---

**Fait avec ‚ù§Ô∏è par l'√©quipe FST Nouakchott**
üéØ COMMANDES FINALES D'EX√âCUTION
Script d'installation automatique complet:
bash
#!/bin/bash
# install.sh - Installation automatique compl√®te

echo "üöÄ Installation Assistant IA Low-Cost"
echo "======================================"

# 1. Collecte donn√©es
echo "üìä √âtape 1: Collecte des donn√©es..."
cd data-collection
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

python 01_scraper_advanced.py
python 03_data_cleaner.py
python 05_embeddings_creator.py

echo "‚úÖ Donn√©es collect√©es"

# 2. Frontend
echo "üì± √âtape 2: Installation frontend..."
cd ../frontend
npm install

echo "‚úÖ Frontend install√©"

# 3. Lancer
echo "üéâ Installation termin√©e!"
echo ""
echo "Pour lancer l'application:"
echo "  cd frontend"
echo "  npm start"
Rendre ex√©cutable:

bash
chmod +x install.sh
./install.sh
‚úÖ CHECKLIST PROJET COMPLET
text
‚úÖ Collecte donn√©es automatique (scraper Selenium)
‚úÖ Extraction PDFs
‚úÖ Nettoyage et structuration donn√©es
‚úÖ G√©n√©ration embeddings multilingues
‚úÖ Quantification mod√®le (optionnel)
‚úÖ Frontend React complet
‚úÖ 3 modes fonctionnels (offline/hybrid/online)
‚úÖ Interface bilingue FR/AR avec RTL
‚úÖ PWA avec Service Worker
‚úÖ IndexedDB pour offline
‚úÖ RAG avec similarit√© s√©mantique
‚úÖ Hooks personnalis√©s
‚úÖ Tests int√©gr√©s
‚úÖ Documentation compl√®te
‚úÖ Configuration d√©ploiement Vercel
‚úÖ README professionnel
‚úÖ Script installation automatique